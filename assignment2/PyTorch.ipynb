{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a ConvNet PyTorch\n",
    "\n",
    "In this notebook, you'll learn how to use the powerful PyTorch framework to specify a conv net architecture and train it on the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's this PyTorch business?\n",
    "\n",
    "You've written a lot of code in this assignment to provide a whole host of neural network functionality. Dropout, Batch Norm, and 2D convolutions are some of the workhorses of deep learning in computer vision. You've also worked hard to make your code efficient and vectorized.\n",
    "\n",
    "For the last part of this assignment, though, we're going to leave behind your beautiful codebase and instead migrate to one of two popular deep learning frameworks: in this instance, PyTorch (or TensorFlow, if you switch over to that notebook). \n",
    "\n",
    "Why?\n",
    "\n",
    "* Our code will now run on GPUs! Much faster training. When using a framework like PyTorch or TensorFlow you can harness the power of the GPU for your own custom neural network architectures without having to write CUDA code directly (which is beyond the scope of this class).\n",
    "* We want you to be ready to use one of these frameworks for your project so you can experiment more efficiently than if you were writing every feature you want to use by hand. \n",
    "* We want you to stand on the shoulders of giants! TensorFlow and PyTorch are both excellent frameworks that will make your lives a lot easier, and now that you understand their guts, you are free to use them :) \n",
    "* We want you to be exposed to the sort of deep learning code you might run into in academia or industry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How will I learn PyTorch?\n",
    "\n",
    "If you've used Torch before, but are new to PyTorch, this tutorial might be of use: http://pytorch.org/tutorials/beginner/former_torchies_tutorial.html\n",
    "\n",
    "Otherwise, this notebook will walk you through much of what you need to do to train models in Torch. See the end of the notebook for some links to helpful tutorials if you want to learn more or need further clarification on topics that aren't fully explained here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets\n",
    "\n",
    "We load the CIFAR-10 dataset. This might take a couple minutes the first time you do it, but the files should stay cached after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.RandomResizedCrop(28),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.Resize(32),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                std = [ 0.229, 0.224, 0.225 ]),\n",
    "])\n",
    "\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                std = [ 0.229, 0.224, 0.225 ]),\n",
    "])\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=train_transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=98, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=test_transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=100, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True,\n",
    "                          transform=test_transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we're going to use a CPU-friendly datatype. Later, we'll switch to a datatype that will move all our computations to the GPU and measure the speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor # the CPU datatype\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "# This is a little utility that we'll use to reset the model\n",
    "# if we want to re-initialize all our parameters\n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Model\n",
    "\n",
    "### Some assorted tidbits\n",
    "\n",
    "Let's start by looking at a simple model. First, note that PyTorch operates on Tensors, which are n-dimensional arrays functionally analogous to numpy's ndarrays, with the additional feature that they can be used for computations on GPUs.\n",
    "\n",
    "We'll provide you with a Flatten function, which we explain here. Remember that our image data (and more relevantly, our intermediate feature maps) are initially N x C x H x W, where:\n",
    "* N is the number of datapoints\n",
    "* C is the number of channels\n",
    "* H is the height of the intermediate feature map in pixels\n",
    "* W is the height of the intermediate feature map in pixels\n",
    "\n",
    "This is the right way to represent the data when we are doing something like a 2D convolution, that needs spatial understanding of where the intermediate features are relative to each other. When we input  data into fully connected affine layers, however, we want each datapoint to be represented by a single vector -- it's no longer useful to segregate the different channels, rows, and columns of the data. So, we use a \"Flatten\" operation to collapse the C x H x W values per representation into a single long vector. The Flatten function below first reads in the N, C, H, and W values from a given batch of data, and then returns a \"view\" of that data. \"View\" is analogous to numpy's \"reshape\" method: it reshapes x's dimensions to be N x ??, where ?? is allowed to be anything (in this case, it will be C x H x W, but we don't need to specify that explicitly). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The example model itself\n",
    "\n",
    "The first step to training your own model is defining its architecture.\n",
    "\n",
    "Here's an example of a convolutional neural network defined in PyTorch -- try to understand what each line is doing, remembering that each layer is composed upon the previous layer. We haven't trained anything yet - that'll come next - for now, we want you to understand how everything gets set up.  nn.Sequential is a container which applies each layer\n",
    "one after the other.\n",
    "\n",
    "In that example, you see 2D convolutional layers (Conv2d), ReLU activations, and fully-connected layers (Linear). You also see the Cross-Entropy loss function, and the Adam optimizer being used. \n",
    "\n",
    "Make sure you understand why the parameters of the Linear layer are 5408 and 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's where we define the architecture of the model... \n",
    "simple_model = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, kernel_size=7, stride=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                Flatten(), # see above for explanation\n",
    "                nn.Linear(5408, 10), # affine layer\n",
    "              )\n",
    "\n",
    "# Set the type of all data in this model to be FloatTensor \n",
    "simple_model.type(dtype)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "optimizer = optim.Adam(simple_model.parameters(), lr=1e-2) # lr sets the learning rate of the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch supports many other layer types, loss functions, and optimizers - you will experiment with these next. Here's the official API documentation for these (if any of the parameters used above were unclear, this resource will also be helpful). One note: what we call in the class \"spatial batch norm\" is called \"BatchNorm2D\" in PyTorch.\n",
    "\n",
    "* Layers: http://pytorch.org/docs/nn.html\n",
    "* Activations: http://pytorch.org/docs/nn.html#non-linear-activations\n",
    "* Loss functions: http://pytorch.org/docs/nn.html#loss-functions\n",
    "* Optimizers: http://pytorch.org/docs/optim.html#algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a specific model\n",
    "\n",
    "In this section, we're going to specify a model for you to construct. The goal here isn't to get good performance (that'll be next), but instead to get comfortable with understanding the PyTorch documentation and configuring your own model. \n",
    "\n",
    "Using the code provided above as guidance, and using the following PyTorch documentation, specify a model with the following architecture:\n",
    "\n",
    "* 7x7 Convolutional Layer with 32 filters and stride of 1\n",
    "* ReLU Activation Layer\n",
    "* Spatial Batch Normalization Layer\n",
    "* 2x2 Max Pooling layer with a stride of 2\n",
    "* Affine layer with 1024 output units\n",
    "* ReLU Activation Layer\n",
    "* Affine layer from 1024 input units to 10 outputs\n",
    "\n",
    "And finally, set up a **cross-entropy** loss function and the **RMSprop** learning rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_model_base = nn.Sequential( # You fill this in!\n",
    "                    nn.Conv2d(3, 32, kernel_size=7, stride=1),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.BatchNorm2d(32, affine=False),\n",
    "                    nn.MaxPool2d(2, stride=2),\n",
    "                    Flatten(),\n",
    "                    nn.Linear(5408, 1024),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(1024, 10),\n",
    "            )\n",
    "\n",
    "fixed_model = fixed_model_base.type(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure you're doing the right thing, use the following tool to check the dimensionality of your output (it should be 64 x 10, since our batches have size 64 and the output of the final affine layer should be 10, corresponding to our 10 classes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now we're going to feed a random batch into the model you defined and make sure the output is the right size\n",
    "x = torch.randn(64, 3, 32, 32).type(dtype)\n",
    "x_var = Variable(x.type(dtype)) # Construct a PyTorch Variable out of your input data\n",
    "ans = fixed_model(x_var)        # Feed it through the model! \n",
    "\n",
    "# Check to make sure what comes out of your model\n",
    "# is the right dimensionality... this should be True\n",
    "# if you've done everything correctly\n",
    "np.array_equal(np.array(ans.size()), np.array([64, 10]))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU!\n",
    "\n",
    "Now, we're going to switch the dtype of the model and our data to the GPU-friendly tensors, and see what happens... everything is the same, except we are casting our model and input tensors as this new dtype instead of the old one.\n",
    "\n",
    "If this returns false, or otherwise fails in a not-graceful way (i.e., with some error message), you may not have an NVIDIA GPU available on your machine. If you're running locally, we recommend you switch to Google Cloud and follow the instructions to set up a GPU there. If you're already on Google Cloud, something is wrong -- make sure you followed the instructions on how to request and use a GPU on your instance. If you did, post on Piazza or come to Office Hours so we can help you debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that CUDA is properly configured and you have a GPU available\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "gpu_dtype = torch.cuda.FloatTensor\n",
    "\n",
    "fixed_model_gpu = copy.deepcopy(fixed_model_base).type(gpu_dtype)\n",
    "\n",
    "x_gpu = torch.randn(64, 3, 32, 32).type(gpu_dtype)\n",
    "x_var_gpu = Variable(x.type(gpu_dtype)) # Construct a PyTorch Variable out of your input data\n",
    "ans = fixed_model_gpu(x_var_gpu)        # Feed it through the model! \n",
    "\n",
    "# Check to make sure what comes out of your model\n",
    "# is the right dimensionality... this should be True\n",
    "# if you've done everything correctly\n",
    "np.array_equal(np.array(ans.size()), np.array([64, 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to evaluate the performance of the forward pass running on the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.8 ms ± 6.12 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "ans = fixed_model(x_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and now the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27 ms ± 17.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "torch.cuda.synchronize() # Make sure there are no pending GPU computations\n",
    "ans = fixed_model_gpu(x_var_gpu)        # Feed it through the model! \n",
    "torch.cuda.synchronize() # Make sure there are no pending GPU computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should observe that even a simple forward pass like this is significantly faster on the GPU. So for the rest of the assignment (and when you go train your models in assignment 3 and your project!), you should use the GPU datatype for your model and your tensors: as a reminder that is *torch.cuda.FloatTensor* (in our notebook here as *gpu_dtype*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model.\n",
    "\n",
    "Now that you've seen how to define a model and do a single forward pass of some data through it, let's  walk through how you'd actually train one whole epoch over your training data (using the simple_model we provided above).\n",
    "\n",
    "Make sure you understand how each PyTorch function used below corresponds to what you implemented in your custom neural network implementation.\n",
    "\n",
    "Note that because we are not resetting the weights anywhere below, if you run the cell multiple times, you are effectively training multiple epochs (so your performance should improve).\n",
    "\n",
    "First, set up an RMSprop optimizer (using a 1e-3 learning rate) and a cross-entropy loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
    "optimizer = optim.RMSprop(fixed_model_gpu.parameters(), lr=1e-3)\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 100, loss = 2.3361\n",
      "t = 200, loss = 2.1028\n",
      "t = 300, loss = 1.8585\n",
      "t = 400, loss = 1.8033\n",
      "t = 500, loss = 1.8755\n"
     ]
    }
   ],
   "source": [
    "# This sets the model in \"training\" mode. This is relevant for some layers that may have different behavior\n",
    "# in training mode vs testing mode, such as Dropout and BatchNorm. \n",
    "fixed_model_gpu.train()\n",
    "\n",
    "# Load one batch at a time.\n",
    "for t, (x, y) in enumerate(loader_train):\n",
    "    x_var = Variable(x.type(gpu_dtype))\n",
    "    y_var = Variable(y.type(gpu_dtype).long())\n",
    "\n",
    "    # This is the forward pass: predict the scores for each class, for each x in the batch.\n",
    "    scores = fixed_model_gpu(x_var)\n",
    "    \n",
    "    # Use the correct y values and the predicted y values to compute the loss.\n",
    "    loss = loss_fn(scores, y_var)\n",
    "    \n",
    "    if (t + 1) % print_every == 0:\n",
    "        print('t = %d, loss = %.4f' % (t + 1, loss.data[0]))\n",
    "\n",
    "    # Zero out all of the gradients for the variables which the optimizer will update.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # This is the backwards pass: compute the gradient of the loss with respect to each \n",
    "    # parameter of the model.\n",
    "    loss.backward()\n",
    "    \n",
    "    # Actually update the parameters of the model using the gradients computed by the backwards pass.\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've seen how the training process works in PyTorch. To save you writing boilerplate code, we're providing the following helper functions to help you train for multiple epochs and check the accuracy of your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, num_epochs = 1, scheduler=None, plot_losses=False):\n",
    "    total_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            x_var = Variable(x.type(gpu_dtype))\n",
    "            y_var = Variable(y.type(gpu_dtype).long())\n",
    "\n",
    "            scores = model(x_var)\n",
    "            \n",
    "            loss = loss_fn(scores, y_var)\n",
    "            losses.append(loss*loader_train.batch_size)\n",
    "            if (t + 1) % print_every == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, np.sum(losses[-print_every:]) / loader_train.batch_size / print_every))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total_losses.append(np.sum(losses)/loader_train.sampler.num_samples)\n",
    "    if plot_losses and len(total_losses) > 1:\n",
    "        plt.grid(True)\n",
    "        plt.title('Result')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.ylim(0,3)\n",
    "        plt.plot(total_losses, label='loss')\n",
    "        plt.show()\n",
    "\n",
    "def check_accuracy(model, loader):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for x, y in loader:\n",
    "        x_var = Variable(x.type(gpu_dtype), volatile=True)\n",
    "\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the accuracy of the model.\n",
    "\n",
    "Let's see the train and check_accuracy code in action -- feel free to use these methods when evaluating the models you develop below.\n",
    "\n",
    "You should get a training loss of around 1.2-1.4, and a validation accuracy of around 50-60%. As mentioned above, if you re-run the cells, you'll be training more epochs, so your performance will improve past these numbers.\n",
    "\n",
    "But don't worry about getting these numbers better -- this was just practice before you tackle designing your own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "t = 100, loss = 4.1495\n",
      "t = 200, loss = 2.0662\n",
      "t = 300, loss = 1.8854\n",
      "t = 400, loss = 1.8565\n",
      "t = 500, loss = 1.8454\n",
      "Checking accuracy on validation set\n",
      "Got 415 / 1000 correct (41.50)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.random.manual_seed(12345)\n",
    "fixed_model_gpu.apply(reset)\n",
    "train(fixed_model_gpu, loss_fn, optimizer, num_epochs=1)\n",
    "check_accuracy(fixed_model_gpu, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't forget the validation set!\n",
    "\n",
    "And note that you can use the check_accuracy function to evaluate on either the test set or the validation set, by passing either **loader_test** or **loader_val** as the second argument to check_accuracy. You should not touch the test set until you have finished your architecture and hyperparameter tuning, and only run the test set once at the end to report a final value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a _great_ model on CIFAR-10!\n",
    "\n",
    "Now it's your job to experiment with architectures, hyperparameters, loss functions, and optimizers to train a model that achieves **>=70%** accuracy on the CIFAR-10 **validation** set. You can use the check_accuracy and train functions from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things you should try:\n",
    "- **Filter size**: Above we used 7x7; this makes pretty pictures but smaller filters may be more efficient\n",
    "- **Number of filters**: Above we used 32 filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use Dropout.\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and regularization strength. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should see improvement within a few hundred iterations\n",
    "- Remember the coarse-to-fine approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "- You should use the validation set for hyperparameter search, and save your test set for evaluating your architecture on the best parameters as selected by the validation set.\n",
    "\n",
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. You are **not required** to implement any of these; however they would be good things to try for extra credit.\n",
    "\n",
    "- Alternative update steps: For the assignment we implemented SGD+momentum, RMSprop, and Adam; you could try alternatives like AdaGrad or AdaDelta.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "\n",
    "If you do decide to implement something extra, clearly describe it in the \"Extra Credit Description\" cell below.\n",
    "\n",
    "### What we expect\n",
    "At the very least, you should be able to train a ConvNet that gets at least 70% accuracy on the validation set. This is just a lower bound - if you are careful it should be possible to get accuracies much higher than that! Extra credit points will be awarded for particularly high-scoring models or unique approaches.\n",
    "\n",
    "You should use the space below to experiment and train your network. \n",
    "\n",
    "Have fun and happy training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 500\n",
      "t = 100, loss = 2.0539\n",
      "t = 200, loss = 1.9163\n",
      "t = 300, loss = 1.8117\n",
      "t = 400, loss = 1.7740\n",
      "t = 500, loss = 1.7434\n",
      "Starting epoch 2 / 500\n",
      "t = 100, loss = 1.6834\n",
      "t = 200, loss = 1.6614\n",
      "t = 300, loss = 1.5933\n",
      "t = 400, loss = 1.5826\n",
      "t = 500, loss = 1.5310\n",
      "Starting epoch 3 / 500\n",
      "t = 100, loss = 1.4884\n",
      "t = 200, loss = 1.4633\n",
      "t = 300, loss = 1.4165\n",
      "t = 400, loss = 1.4221\n",
      "t = 500, loss = 1.3926\n",
      "Starting epoch 4 / 500\n",
      "t = 100, loss = 1.3717\n",
      "t = 200, loss = 1.3497\n",
      "t = 300, loss = 1.3200\n",
      "t = 400, loss = 1.3251\n",
      "t = 500, loss = 1.3119\n",
      "Starting epoch 5 / 500\n",
      "t = 100, loss = 1.2786\n",
      "t = 200, loss = 1.2829\n",
      "t = 300, loss = 1.2667\n",
      "t = 400, loss = 1.2543\n",
      "t = 500, loss = 1.2533\n",
      "Starting epoch 6 / 500\n",
      "t = 100, loss = 1.2238\n",
      "t = 200, loss = 1.2473\n",
      "t = 300, loss = 1.2066\n",
      "t = 400, loss = 1.2097\n",
      "t = 500, loss = 1.2016\n",
      "Starting epoch 7 / 500\n",
      "t = 100, loss = 1.1844\n",
      "t = 200, loss = 1.1999\n",
      "t = 300, loss = 1.1463\n",
      "t = 400, loss = 1.1814\n",
      "t = 500, loss = 1.1494\n",
      "Starting epoch 8 / 500\n",
      "t = 100, loss = 1.1430\n",
      "t = 200, loss = 1.1470\n",
      "t = 300, loss = 1.1432\n",
      "t = 400, loss = 1.1276\n",
      "t = 500, loss = 1.1402\n",
      "Starting epoch 9 / 500\n",
      "t = 100, loss = 1.1270\n",
      "t = 200, loss = 1.1376\n",
      "t = 300, loss = 1.1140\n",
      "t = 400, loss = 1.1281\n",
      "t = 500, loss = 1.0961\n",
      "Starting epoch 10 / 500\n",
      "t = 100, loss = 1.1002\n",
      "t = 200, loss = 1.1176\n",
      "t = 300, loss = 1.1154\n",
      "t = 400, loss = 1.1097\n",
      "t = 500, loss = 1.0955\n",
      "Starting epoch 11 / 500\n",
      "t = 100, loss = 1.0733\n",
      "t = 200, loss = 1.1046\n",
      "t = 300, loss = 1.0841\n",
      "t = 400, loss = 1.1047\n",
      "t = 500, loss = 1.0823\n",
      "Starting epoch 12 / 500\n",
      "t = 100, loss = 1.0756\n",
      "t = 200, loss = 1.0766\n",
      "t = 300, loss = 1.0781\n",
      "t = 400, loss = 1.0838\n",
      "t = 500, loss = 1.0656\n",
      "Starting epoch 13 / 500\n",
      "t = 100, loss = 1.0523\n",
      "t = 200, loss = 1.0825\n",
      "t = 300, loss = 1.0839\n",
      "t = 400, loss = 1.0559\n",
      "t = 500, loss = 1.0549\n",
      "Starting epoch 14 / 500\n",
      "t = 100, loss = 1.0396\n",
      "t = 200, loss = 1.0637\n",
      "t = 300, loss = 1.0555\n",
      "t = 400, loss = 1.0515\n",
      "t = 500, loss = 1.0450\n",
      "Starting epoch 15 / 500\n",
      "t = 100, loss = 1.0439\n",
      "t = 200, loss = 1.0644\n",
      "t = 300, loss = 1.0534\n",
      "t = 400, loss = 1.0515\n",
      "t = 500, loss = 1.0363\n",
      "Starting epoch 16 / 500\n",
      "t = 100, loss = 1.0247\n",
      "t = 200, loss = 1.0492\n",
      "t = 300, loss = 1.0532\n",
      "t = 400, loss = 1.0346\n",
      "t = 500, loss = 1.0418\n",
      "Starting epoch 17 / 500\n",
      "t = 100, loss = 1.0241\n",
      "t = 200, loss = 1.0241\n",
      "t = 300, loss = 1.0371\n",
      "t = 400, loss = 1.0297\n",
      "t = 500, loss = 1.0336\n",
      "Starting epoch 18 / 500\n",
      "t = 100, loss = 1.0300\n",
      "t = 200, loss = 1.0357\n",
      "t = 300, loss = 1.0193\n",
      "t = 400, loss = 1.0426\n",
      "t = 500, loss = 1.0127\n",
      "Starting epoch 19 / 500\n",
      "t = 100, loss = 1.0210\n",
      "t = 200, loss = 1.0146\n",
      "t = 300, loss = 1.0156\n",
      "t = 400, loss = 1.0341\n",
      "t = 500, loss = 1.0017\n",
      "Starting epoch 20 / 500\n",
      "t = 100, loss = 1.0006\n",
      "t = 200, loss = 1.0377\n",
      "t = 300, loss = 0.9909\n",
      "t = 400, loss = 1.0135\n",
      "t = 500, loss = 1.0164\n",
      "Starting epoch 21 / 500\n",
      "t = 100, loss = 1.0052\n",
      "t = 200, loss = 1.0396\n",
      "t = 300, loss = 1.0031\n",
      "t = 400, loss = 1.0138\n",
      "t = 500, loss = 1.0026\n",
      "Starting epoch 22 / 500\n",
      "t = 100, loss = 0.9965\n",
      "t = 200, loss = 1.0078\n",
      "t = 300, loss = 0.9942\n",
      "t = 400, loss = 1.0046\n",
      "t = 500, loss = 0.9858\n",
      "Starting epoch 23 / 500\n",
      "t = 100, loss = 1.0015\n",
      "t = 200, loss = 1.0083\n",
      "t = 300, loss = 0.9923\n",
      "t = 400, loss = 1.0163\n",
      "t = 500, loss = 1.0172\n",
      "Starting epoch 24 / 500\n",
      "t = 100, loss = 0.9963\n",
      "t = 200, loss = 1.0116\n",
      "t = 300, loss = 0.9957\n",
      "t = 400, loss = 0.9966\n",
      "t = 500, loss = 0.9942\n",
      "Starting epoch 25 / 500\n",
      "t = 100, loss = 0.9773\n",
      "t = 200, loss = 1.0063\n",
      "t = 300, loss = 0.9799\n",
      "t = 400, loss = 0.9992\n",
      "t = 500, loss = 0.9824\n",
      "Starting epoch 26 / 500\n",
      "t = 100, loss = 1.0076\n",
      "t = 200, loss = 1.0017\n",
      "t = 300, loss = 0.9751\n",
      "t = 400, loss = 1.0005\n",
      "t = 500, loss = 0.9891\n",
      "Starting epoch 27 / 500\n",
      "t = 100, loss = 0.9742\n",
      "t = 200, loss = 1.0033\n",
      "t = 300, loss = 0.9785\n",
      "t = 400, loss = 0.9982\n",
      "t = 500, loss = 0.9694\n",
      "Starting epoch 28 / 500\n",
      "t = 100, loss = 0.9777\n",
      "t = 200, loss = 0.9925\n",
      "t = 300, loss = 0.9917\n",
      "t = 400, loss = 0.9886\n",
      "t = 500, loss = 0.9764\n",
      "Starting epoch 29 / 500\n",
      "t = 100, loss = 0.9706\n",
      "t = 200, loss = 0.9930\n",
      "t = 300, loss = 0.9752\n",
      "t = 400, loss = 0.9861\n",
      "t = 500, loss = 0.9874\n",
      "Starting epoch 30 / 500\n",
      "t = 100, loss = 0.9965\n",
      "t = 200, loss = 0.9937\n",
      "t = 300, loss = 0.9826\n",
      "t = 400, loss = 0.9974\n",
      "t = 500, loss = 0.9717\n",
      "Starting epoch 31 / 500\n",
      "t = 100, loss = 0.9629\n",
      "t = 200, loss = 0.9849\n",
      "t = 300, loss = 0.9829\n",
      "t = 400, loss = 0.9956\n",
      "t = 500, loss = 0.9659\n",
      "Starting epoch 32 / 500\n",
      "t = 100, loss = 0.9854\n",
      "t = 200, loss = 0.9951\n",
      "t = 300, loss = 0.9874\n",
      "t = 400, loss = 0.9719\n",
      "t = 500, loss = 0.9772\n",
      "Starting epoch 33 / 500\n",
      "t = 100, loss = 0.9629\n",
      "t = 200, loss = 0.9898\n",
      "t = 300, loss = 0.9542\n",
      "t = 400, loss = 0.9700\n",
      "t = 500, loss = 0.9640\n",
      "Starting epoch 34 / 500\n",
      "t = 100, loss = 0.9679\n",
      "t = 200, loss = 0.9754\n",
      "t = 300, loss = 0.9733\n",
      "t = 400, loss = 0.9768\n",
      "t = 500, loss = 0.9810\n",
      "Starting epoch 35 / 500\n",
      "t = 100, loss = 0.9630\n",
      "t = 200, loss = 0.9832\n",
      "t = 300, loss = 0.9667\n",
      "t = 400, loss = 0.9750\n",
      "t = 500, loss = 0.9642\n",
      "Starting epoch 36 / 500\n",
      "t = 100, loss = 0.9668\n",
      "t = 200, loss = 0.9708\n",
      "t = 300, loss = 0.9612\n",
      "t = 400, loss = 0.9681\n",
      "t = 500, loss = 0.9536\n",
      "Starting epoch 37 / 500\n",
      "t = 100, loss = 0.9606\n",
      "t = 200, loss = 0.9639\n",
      "t = 300, loss = 0.9792\n",
      "t = 400, loss = 0.9765\n",
      "t = 500, loss = 0.9550\n",
      "Starting epoch 38 / 500\n",
      "t = 100, loss = 0.9698\n",
      "t = 200, loss = 0.9872\n",
      "t = 300, loss = 0.9472\n",
      "t = 400, loss = 0.9818\n",
      "t = 500, loss = 0.9551\n",
      "Starting epoch 39 / 500\n",
      "t = 100, loss = 0.9617\n",
      "t = 200, loss = 0.9728\n",
      "t = 300, loss = 0.9551\n",
      "t = 400, loss = 0.9645\n",
      "t = 500, loss = 0.9653\n",
      "Starting epoch 40 / 500\n",
      "t = 100, loss = 0.9605\n",
      "t = 200, loss = 0.9706\n",
      "t = 300, loss = 0.9524\n",
      "t = 400, loss = 0.9572\n",
      "t = 500, loss = 0.9430\n",
      "Starting epoch 41 / 500\n",
      "t = 100, loss = 0.9575\n",
      "t = 200, loss = 0.9776\n",
      "t = 300, loss = 0.9602\n",
      "t = 400, loss = 0.9709\n",
      "t = 500, loss = 0.9695\n",
      "Starting epoch 42 / 500\n",
      "t = 100, loss = 0.9530\n",
      "t = 200, loss = 0.9731\n",
      "t = 300, loss = 0.9544\n",
      "t = 400, loss = 0.9610\n",
      "t = 500, loss = 0.9575\n",
      "Starting epoch 43 / 500\n",
      "t = 100, loss = 0.9594\n",
      "t = 200, loss = 0.9605\n",
      "t = 300, loss = 0.9529\n",
      "t = 400, loss = 0.9617\n",
      "t = 500, loss = 0.9561\n",
      "Starting epoch 44 / 500\n",
      "t = 100, loss = 0.9561\n",
      "t = 200, loss = 0.9640\n",
      "t = 300, loss = 0.9574\n",
      "t = 400, loss = 0.9601\n",
      "t = 500, loss = 0.9492\n",
      "Starting epoch 45 / 500\n",
      "t = 100, loss = 0.9495\n",
      "t = 200, loss = 0.9627\n",
      "t = 300, loss = 0.9471\n",
      "t = 400, loss = 0.9747\n",
      "t = 500, loss = 0.9414\n",
      "Starting epoch 46 / 500\n",
      "t = 100, loss = 0.9662\n",
      "t = 200, loss = 0.9579\n",
      "t = 300, loss = 0.9423\n",
      "t = 400, loss = 0.9543\n",
      "t = 500, loss = 0.9692\n",
      "Starting epoch 47 / 500\n",
      "t = 100, loss = 0.9615\n",
      "t = 200, loss = 0.9812\n",
      "t = 300, loss = 0.9638\n",
      "t = 400, loss = 0.9830\n",
      "t = 500, loss = 0.9446\n",
      "Starting epoch 48 / 500\n",
      "t = 100, loss = 0.9394\n",
      "t = 200, loss = 0.9649\n",
      "t = 300, loss = 0.9429\n",
      "t = 400, loss = 0.9731\n",
      "t = 500, loss = 0.9526\n",
      "Starting epoch 49 / 500\n",
      "t = 100, loss = 0.9545\n",
      "t = 200, loss = 0.9759\n",
      "t = 300, loss = 0.9536\n",
      "t = 400, loss = 0.9611\n",
      "t = 500, loss = 0.9493\n",
      "Starting epoch 50 / 500\n",
      "t = 100, loss = 0.9609\n",
      "t = 200, loss = 0.9417\n",
      "t = 300, loss = 0.9528\n",
      "t = 400, loss = 0.9542\n",
      "t = 500, loss = 0.9588\n",
      "Starting epoch 51 / 500\n",
      "t = 100, loss = 0.9524\n",
      "t = 200, loss = 0.9666\n",
      "t = 300, loss = 0.9513\n",
      "t = 400, loss = 0.9526\n",
      "t = 500, loss = 0.9542\n",
      "Starting epoch 52 / 500\n",
      "t = 100, loss = 0.9423\n",
      "t = 200, loss = 0.9500\n",
      "t = 300, loss = 0.9412\n",
      "t = 400, loss = 0.9523\n",
      "t = 500, loss = 0.9510\n",
      "Starting epoch 53 / 500\n",
      "t = 100, loss = 0.9396\n",
      "t = 200, loss = 0.9688\n",
      "t = 300, loss = 0.9562\n",
      "t = 400, loss = 0.9619\n",
      "t = 500, loss = 0.9450\n",
      "Starting epoch 54 / 500\n",
      "t = 100, loss = 0.9375\n",
      "t = 200, loss = 0.9614\n",
      "t = 300, loss = 0.9324\n",
      "t = 400, loss = 0.9463\n",
      "t = 500, loss = 0.9368\n",
      "Starting epoch 55 / 500\n",
      "t = 100, loss = 0.9361\n",
      "t = 200, loss = 0.9577\n",
      "t = 300, loss = 0.9495\n",
      "t = 400, loss = 0.9452\n",
      "t = 500, loss = 0.9482\n",
      "Starting epoch 56 / 500\n",
      "t = 100, loss = 0.9366\n",
      "t = 200, loss = 0.9543\n",
      "t = 300, loss = 0.9635\n",
      "t = 400, loss = 0.9450\n",
      "t = 500, loss = 0.9347\n",
      "Starting epoch 57 / 500\n",
      "t = 100, loss = 0.9312\n",
      "t = 200, loss = 0.9461\n",
      "t = 300, loss = 0.9464\n",
      "t = 400, loss = 0.9619\n",
      "t = 500, loss = 0.9455\n",
      "Starting epoch 58 / 500\n",
      "t = 100, loss = 0.9448\n",
      "t = 200, loss = 0.9601\n",
      "t = 300, loss = 0.9446\n",
      "t = 400, loss = 0.9406\n",
      "t = 500, loss = 0.9457\n",
      "Starting epoch 59 / 500\n",
      "t = 100, loss = 0.9387\n",
      "t = 200, loss = 0.9521\n",
      "t = 300, loss = 0.9494\n",
      "t = 400, loss = 0.9694\n",
      "t = 500, loss = 0.9481\n",
      "Starting epoch 60 / 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 100, loss = 0.9295\n",
      "t = 200, loss = 0.9685\n",
      "t = 300, loss = 0.9173\n",
      "t = 400, loss = 0.9669\n",
      "t = 500, loss = 0.9626\n",
      "Starting epoch 61 / 500\n",
      "t = 100, loss = 0.9447\n",
      "t = 200, loss = 0.9572\n",
      "t = 300, loss = 0.9175\n",
      "t = 400, loss = 0.9575\n",
      "t = 500, loss = 0.9364\n",
      "Starting epoch 62 / 500\n",
      "t = 100, loss = 0.9541\n",
      "t = 200, loss = 0.9569\n",
      "t = 300, loss = 0.9388\n",
      "t = 400, loss = 0.9589\n",
      "t = 500, loss = 0.9360\n",
      "Starting epoch 63 / 500\n",
      "t = 100, loss = 0.9465\n",
      "t = 200, loss = 0.9550\n",
      "t = 300, loss = 0.9269\n",
      "t = 400, loss = 0.9463\n",
      "t = 500, loss = 0.9613\n",
      "Starting epoch 64 / 500\n",
      "t = 100, loss = 0.9345\n",
      "t = 200, loss = 0.9368\n",
      "t = 300, loss = 0.9281\n",
      "t = 400, loss = 0.9479\n",
      "t = 500, loss = 0.9551\n",
      "Starting epoch 65 / 500\n",
      "t = 100, loss = 0.9388\n",
      "t = 200, loss = 0.9527\n",
      "t = 300, loss = 0.9431\n",
      "t = 400, loss = 0.9559\n",
      "t = 500, loss = 0.9284\n",
      "Starting epoch 66 / 500\n",
      "t = 100, loss = 0.9608\n",
      "t = 200, loss = 0.9313\n",
      "t = 300, loss = 0.9417\n",
      "t = 400, loss = 0.9700\n",
      "t = 500, loss = 0.9438\n",
      "Starting epoch 67 / 500\n",
      "t = 100, loss = 0.9218\n",
      "t = 200, loss = 0.9546\n",
      "t = 300, loss = 0.9323\n",
      "t = 400, loss = 0.9607\n",
      "t = 500, loss = 0.9530\n",
      "Starting epoch 68 / 500\n",
      "t = 100, loss = 0.9326\n",
      "t = 200, loss = 0.9447\n",
      "t = 300, loss = 0.9382\n",
      "t = 400, loss = 0.9525\n",
      "t = 500, loss = 0.9363\n",
      "Starting epoch 69 / 500\n",
      "t = 100, loss = 0.9496\n",
      "t = 200, loss = 0.9359\n",
      "t = 300, loss = 0.9307\n",
      "t = 400, loss = 0.9401\n",
      "t = 500, loss = 0.9584\n",
      "Starting epoch 70 / 500\n",
      "t = 100, loss = 0.9257\n",
      "t = 200, loss = 0.9382\n",
      "t = 300, loss = 0.9367\n",
      "t = 400, loss = 0.9460\n",
      "t = 500, loss = 0.9564\n",
      "Starting epoch 71 / 500\n",
      "t = 100, loss = 0.9450\n",
      "t = 200, loss = 0.9276\n",
      "t = 300, loss = 0.9344\n",
      "t = 400, loss = 0.9433\n",
      "t = 500, loss = 0.9418\n",
      "Starting epoch 72 / 500\n",
      "t = 100, loss = 0.9416\n",
      "t = 200, loss = 0.9242\n",
      "t = 300, loss = 0.9202\n",
      "t = 400, loss = 0.9465\n",
      "t = 500, loss = 0.9391\n",
      "Starting epoch 73 / 500\n",
      "t = 100, loss = 0.9417\n",
      "t = 200, loss = 0.9617\n",
      "t = 300, loss = 0.9530\n",
      "t = 400, loss = 0.9384\n",
      "t = 500, loss = 0.9416\n",
      "Starting epoch 74 / 500\n",
      "t = 100, loss = 0.9301\n",
      "t = 200, loss = 0.9462\n",
      "t = 300, loss = 0.9562\n",
      "t = 400, loss = 0.9420\n",
      "t = 500, loss = 0.9223\n",
      "Starting epoch 75 / 500\n",
      "t = 100, loss = 0.9366\n",
      "t = 200, loss = 0.9499\n",
      "t = 300, loss = 0.9410\n",
      "t = 400, loss = 0.9472\n",
      "t = 500, loss = 0.9228\n",
      "Starting epoch 76 / 500\n",
      "t = 100, loss = 0.9448\n",
      "t = 200, loss = 0.9385\n",
      "t = 300, loss = 0.9497\n",
      "t = 400, loss = 0.9346\n",
      "t = 500, loss = 0.9467\n",
      "Starting epoch 77 / 500\n",
      "t = 100, loss = 0.9223\n",
      "t = 200, loss = 0.9378\n",
      "t = 300, loss = 0.9471\n",
      "t = 400, loss = 0.9465\n",
      "t = 500, loss = 0.9445\n",
      "Starting epoch 78 / 500\n",
      "t = 100, loss = 0.9357\n",
      "t = 200, loss = 0.9495\n",
      "t = 300, loss = 0.9461\n",
      "t = 400, loss = 0.9499\n",
      "t = 500, loss = 0.9404\n",
      "Starting epoch 79 / 500\n",
      "t = 100, loss = 0.9387\n",
      "t = 200, loss = 0.9412\n",
      "t = 300, loss = 0.9295\n",
      "t = 400, loss = 0.9411\n",
      "t = 500, loss = 0.9467\n",
      "Starting epoch 80 / 500\n",
      "t = 100, loss = 0.9359\n",
      "t = 200, loss = 0.9688\n",
      "t = 300, loss = 0.9217\n",
      "t = 400, loss = 0.9494\n",
      "t = 500, loss = 0.9456\n",
      "Starting epoch 81 / 500\n",
      "t = 100, loss = 0.9288\n",
      "t = 200, loss = 0.9572\n",
      "t = 300, loss = 0.9257\n",
      "t = 400, loss = 0.9499\n",
      "t = 500, loss = 0.9247\n",
      "Starting epoch 82 / 500\n",
      "t = 100, loss = 0.9441\n",
      "t = 200, loss = 0.9571\n",
      "t = 300, loss = 0.9247\n",
      "t = 400, loss = 0.9371\n",
      "t = 500, loss = 0.9524\n",
      "Starting epoch 83 / 500\n",
      "t = 100, loss = 0.9386\n",
      "t = 200, loss = 0.9419\n",
      "t = 300, loss = 0.9387\n",
      "t = 400, loss = 0.9527\n",
      "t = 500, loss = 0.9305\n",
      "Starting epoch 84 / 500\n",
      "t = 100, loss = 0.9105\n",
      "t = 200, loss = 0.9465\n",
      "t = 300, loss = 0.9261\n",
      "t = 400, loss = 0.9459\n",
      "t = 500, loss = 0.9450\n",
      "Starting epoch 85 / 500\n",
      "t = 100, loss = 0.9346\n",
      "t = 200, loss = 0.9489\n",
      "t = 300, loss = 0.9222\n",
      "t = 400, loss = 0.9507\n",
      "t = 500, loss = 0.9454\n",
      "Starting epoch 86 / 500\n",
      "t = 100, loss = 0.9236\n",
      "t = 200, loss = 0.9623\n",
      "t = 300, loss = 0.9343\n",
      "t = 400, loss = 0.9383\n",
      "t = 500, loss = 0.9266\n",
      "Starting epoch 87 / 500\n",
      "t = 100, loss = 0.9432\n",
      "t = 200, loss = 0.9477\n",
      "t = 300, loss = 0.9302\n",
      "t = 400, loss = 0.9492\n",
      "t = 500, loss = 0.9295\n",
      "Starting epoch 88 / 500\n",
      "t = 100, loss = 0.9155\n",
      "t = 200, loss = 0.9372\n",
      "t = 300, loss = 0.9301\n",
      "t = 400, loss = 0.9399\n",
      "t = 500, loss = 0.9305\n",
      "Starting epoch 89 / 500\n",
      "t = 100, loss = 0.9301\n",
      "t = 200, loss = 0.9430\n",
      "t = 300, loss = 0.9398\n",
      "t = 400, loss = 0.9485\n",
      "t = 500, loss = 0.9565\n",
      "Starting epoch 90 / 500\n",
      "t = 100, loss = 0.9426\n",
      "t = 200, loss = 0.9459\n",
      "t = 300, loss = 0.9119\n",
      "t = 400, loss = 0.9496\n",
      "t = 500, loss = 0.9331\n",
      "Starting epoch 91 / 500\n",
      "t = 100, loss = 0.9217\n",
      "t = 200, loss = 0.9215\n",
      "t = 300, loss = 0.9218\n",
      "t = 400, loss = 0.9498\n",
      "t = 500, loss = 0.9568\n",
      "Starting epoch 92 / 500\n",
      "t = 100, loss = 0.9022\n",
      "t = 200, loss = 0.9570\n",
      "t = 300, loss = 0.9391\n",
      "t = 400, loss = 0.9363\n",
      "t = 500, loss = 0.9232\n",
      "Starting epoch 93 / 500\n",
      "t = 100, loss = 0.9375\n",
      "t = 200, loss = 0.9357\n",
      "t = 300, loss = 0.9375\n",
      "t = 400, loss = 0.9354\n",
      "t = 500, loss = 0.9260\n",
      "Starting epoch 94 / 500\n",
      "t = 100, loss = 0.9134\n",
      "t = 200, loss = 0.9567\n",
      "t = 300, loss = 0.9183\n",
      "t = 400, loss = 0.9336\n",
      "t = 500, loss = 0.9457\n",
      "Starting epoch 95 / 500\n",
      "t = 100, loss = 0.9344\n",
      "t = 200, loss = 0.9397\n",
      "t = 300, loss = 0.9127\n",
      "t = 400, loss = 0.9440\n",
      "t = 500, loss = 0.9235\n",
      "Starting epoch 96 / 500\n",
      "t = 100, loss = 0.9173\n",
      "t = 200, loss = 0.9423\n",
      "t = 300, loss = 0.9360\n",
      "t = 400, loss = 0.9440\n",
      "t = 500, loss = 0.9490\n",
      "Starting epoch 97 / 500\n",
      "t = 100, loss = 0.9404\n",
      "t = 200, loss = 0.9298\n",
      "t = 300, loss = 0.9321\n",
      "t = 400, loss = 0.9546\n",
      "t = 500, loss = 0.9380\n",
      "Starting epoch 98 / 500\n",
      "t = 100, loss = 0.9345\n",
      "t = 200, loss = 0.9477\n",
      "t = 300, loss = 0.9184\n",
      "t = 400, loss = 0.9463\n",
      "t = 500, loss = 0.9588\n",
      "Starting epoch 99 / 500\n",
      "t = 100, loss = 0.9289\n",
      "t = 200, loss = 0.9412\n",
      "t = 300, loss = 0.9295\n",
      "t = 400, loss = 0.9378\n",
      "t = 500, loss = 0.9330\n",
      "Starting epoch 100 / 500\n",
      "t = 100, loss = 0.9291\n",
      "t = 200, loss = 0.9506\n",
      "t = 300, loss = 0.9333\n",
      "t = 400, loss = 0.9165\n",
      "t = 500, loss = 0.9377\n",
      "Starting epoch 101 / 500\n",
      "t = 100, loss = 0.8233\n",
      "t = 200, loss = 0.7836\n",
      "t = 300, loss = 0.7303\n",
      "t = 400, loss = 0.7229\n",
      "t = 500, loss = 0.6935\n",
      "Starting epoch 102 / 500\n",
      "t = 100, loss = 0.7048\n",
      "t = 200, loss = 0.7131\n",
      "t = 300, loss = 0.6854\n",
      "t = 400, loss = 0.6727\n",
      "t = 500, loss = 0.6701\n",
      "Starting epoch 103 / 500\n",
      "t = 100, loss = 0.6737\n",
      "t = 200, loss = 0.6789\n",
      "t = 300, loss = 0.6527\n",
      "t = 400, loss = 0.6628\n",
      "t = 500, loss = 0.6528\n",
      "Starting epoch 104 / 500\n",
      "t = 100, loss = 0.6493\n",
      "t = 200, loss = 0.6482\n",
      "t = 300, loss = 0.6278\n",
      "t = 400, loss = 0.6545\n",
      "t = 500, loss = 0.6380\n",
      "Starting epoch 105 / 500\n",
      "t = 100, loss = 0.6443\n",
      "t = 200, loss = 0.6555\n",
      "t = 300, loss = 0.6211\n",
      "t = 400, loss = 0.6526\n",
      "t = 500, loss = 0.6343\n",
      "Starting epoch 106 / 500\n",
      "t = 100, loss = 0.6351\n",
      "t = 200, loss = 0.6351\n",
      "t = 300, loss = 0.6093\n",
      "t = 400, loss = 0.6300\n",
      "t = 500, loss = 0.6257\n",
      "Starting epoch 107 / 500\n",
      "t = 100, loss = 0.6377\n",
      "t = 200, loss = 0.6288\n",
      "t = 300, loss = 0.6218\n",
      "t = 400, loss = 0.6146\n",
      "t = 500, loss = 0.6202\n",
      "Starting epoch 108 / 500\n",
      "t = 100, loss = 0.6200\n",
      "t = 200, loss = 0.6244\n",
      "t = 300, loss = 0.6026\n",
      "t = 400, loss = 0.6260\n",
      "t = 500, loss = 0.5955\n",
      "Starting epoch 109 / 500\n",
      "t = 100, loss = 0.6048\n",
      "t = 200, loss = 0.6227\n",
      "t = 300, loss = 0.5989\n",
      "t = 400, loss = 0.6101\n",
      "t = 500, loss = 0.6065\n",
      "Starting epoch 110 / 500\n",
      "t = 100, loss = 0.6085\n",
      "t = 200, loss = 0.6096\n",
      "t = 300, loss = 0.6142\n",
      "t = 400, loss = 0.6100\n",
      "t = 500, loss = 0.5995\n",
      "Starting epoch 111 / 500\n",
      "t = 100, loss = 0.6086\n",
      "t = 200, loss = 0.6093\n",
      "t = 300, loss = 0.5863\n",
      "t = 400, loss = 0.6093\n",
      "t = 500, loss = 0.6053\n",
      "Starting epoch 112 / 500\n",
      "t = 100, loss = 0.5989\n",
      "t = 200, loss = 0.5979\n",
      "t = 300, loss = 0.5990\n",
      "t = 400, loss = 0.5928\n",
      "t = 500, loss = 0.6140\n",
      "Starting epoch 113 / 500\n",
      "t = 100, loss = 0.6022\n",
      "t = 200, loss = 0.6146\n",
      "t = 300, loss = 0.5829\n",
      "t = 400, loss = 0.5952\n",
      "t = 500, loss = 0.5773\n",
      "Starting epoch 114 / 500\n",
      "t = 100, loss = 0.5937\n",
      "t = 200, loss = 0.6069\n",
      "t = 300, loss = 0.5845\n",
      "t = 400, loss = 0.5934\n",
      "t = 500, loss = 0.5921\n",
      "Starting epoch 115 / 500\n",
      "t = 100, loss = 0.5808\n",
      "t = 200, loss = 0.6007\n",
      "t = 300, loss = 0.5806\n",
      "t = 400, loss = 0.6128\n",
      "t = 500, loss = 0.5921\n",
      "Starting epoch 116 / 500\n",
      "t = 100, loss = 0.5971\n",
      "t = 200, loss = 0.6024\n",
      "t = 300, loss = 0.5945\n",
      "t = 400, loss = 0.5898\n",
      "t = 500, loss = 0.5847\n",
      "Starting epoch 117 / 500\n",
      "t = 100, loss = 0.5767\n",
      "t = 200, loss = 0.5991\n",
      "t = 300, loss = 0.5874\n",
      "t = 400, loss = 0.6054\n",
      "t = 500, loss = 0.5930\n",
      "Starting epoch 118 / 500\n",
      "t = 100, loss = 0.5864\n",
      "t = 200, loss = 0.5870\n",
      "t = 300, loss = 0.5742\n",
      "t = 400, loss = 0.5957\n",
      "t = 500, loss = 0.5866\n",
      "Starting epoch 119 / 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 100, loss = 0.5918\n",
      "t = 200, loss = 0.5867\n",
      "t = 300, loss = 0.5916\n",
      "t = 400, loss = 0.5805\n",
      "t = 500, loss = 0.5873\n",
      "Starting epoch 120 / 500\n",
      "t = 100, loss = 0.5837\n",
      "t = 200, loss = 0.6044\n",
      "t = 300, loss = 0.5912\n",
      "t = 400, loss = 0.5997\n",
      "t = 500, loss = 0.5822\n",
      "Starting epoch 121 / 500\n",
      "t = 100, loss = 0.5942\n",
      "t = 200, loss = 0.5980\n",
      "t = 300, loss = 0.5806\n",
      "t = 400, loss = 0.5976\n",
      "t = 500, loss = 0.5813\n",
      "Starting epoch 122 / 500\n",
      "t = 100, loss = 0.5721\n",
      "t = 200, loss = 0.5853\n",
      "t = 300, loss = 0.5829\n",
      "t = 400, loss = 0.6073\n",
      "t = 500, loss = 0.5866\n",
      "Starting epoch 123 / 500\n",
      "t = 100, loss = 0.5826\n",
      "t = 200, loss = 0.5893\n",
      "t = 300, loss = 0.5800\n",
      "t = 400, loss = 0.6004\n",
      "t = 500, loss = 0.5947\n",
      "Starting epoch 124 / 500\n",
      "t = 100, loss = 0.5711\n",
      "t = 200, loss = 0.6088\n",
      "t = 300, loss = 0.5921\n",
      "t = 400, loss = 0.5920\n",
      "t = 500, loss = 0.5994\n",
      "Starting epoch 125 / 500\n",
      "t = 100, loss = 0.5796\n",
      "t = 200, loss = 0.5998\n",
      "t = 300, loss = 0.5889\n",
      "t = 400, loss = 0.5813\n",
      "t = 500, loss = 0.5834\n",
      "Starting epoch 126 / 500\n",
      "t = 100, loss = 0.5725\n",
      "t = 200, loss = 0.5914\n",
      "t = 300, loss = 0.5606\n",
      "t = 400, loss = 0.5884\n",
      "t = 500, loss = 0.5797\n",
      "Starting epoch 127 / 500\n",
      "t = 100, loss = 0.5958\n",
      "t = 200, loss = 0.6095\n",
      "t = 300, loss = 0.5792\n",
      "t = 400, loss = 0.5960\n",
      "t = 500, loss = 0.5741\n",
      "Starting epoch 128 / 500\n",
      "t = 100, loss = 0.5853\n",
      "t = 200, loss = 0.5996\n",
      "t = 300, loss = 0.5792\n",
      "t = 400, loss = 0.5977\n",
      "t = 500, loss = 0.5942\n",
      "Starting epoch 129 / 500\n",
      "t = 100, loss = 0.5749\n",
      "t = 200, loss = 0.6041\n",
      "t = 300, loss = 0.5788\n",
      "t = 400, loss = 0.5945\n",
      "t = 500, loss = 0.5873\n",
      "Starting epoch 130 / 500\n",
      "t = 100, loss = 0.5734\n",
      "t = 200, loss = 0.5796\n",
      "t = 300, loss = 0.5701\n",
      "t = 400, loss = 0.5918\n",
      "t = 500, loss = 0.5832\n",
      "Starting epoch 131 / 500\n",
      "t = 100, loss = 0.5855\n",
      "t = 200, loss = 0.5843\n",
      "t = 300, loss = 0.5728\n",
      "t = 400, loss = 0.5868\n",
      "t = 500, loss = 0.5878\n",
      "Starting epoch 132 / 500\n",
      "t = 100, loss = 0.5747\n",
      "t = 200, loss = 0.6132\n",
      "t = 300, loss = 0.5772\n",
      "t = 400, loss = 0.5783\n",
      "t = 500, loss = 0.5780\n",
      "Starting epoch 133 / 500\n",
      "t = 100, loss = 0.5817\n",
      "t = 200, loss = 0.6036\n",
      "t = 300, loss = 0.5752\n",
      "t = 400, loss = 0.5758\n",
      "t = 500, loss = 0.5790\n",
      "Starting epoch 134 / 500\n",
      "t = 100, loss = 0.5766\n",
      "t = 200, loss = 0.5882\n",
      "t = 300, loss = 0.5771\n",
      "t = 400, loss = 0.5936\n",
      "t = 500, loss = 0.5960\n",
      "Starting epoch 135 / 500\n",
      "t = 100, loss = 0.5755\n",
      "t = 200, loss = 0.5986\n",
      "t = 300, loss = 0.5682\n",
      "t = 400, loss = 0.5964\n",
      "t = 500, loss = 0.5976\n",
      "Starting epoch 136 / 500\n",
      "t = 100, loss = 0.5779\n",
      "t = 200, loss = 0.6038\n",
      "t = 300, loss = 0.5752\n",
      "t = 400, loss = 0.5733\n",
      "t = 500, loss = 0.5822\n",
      "Starting epoch 137 / 500\n",
      "t = 100, loss = 0.5841\n",
      "t = 200, loss = 0.5957\n",
      "t = 300, loss = 0.5520\n",
      "t = 400, loss = 0.5968\n",
      "t = 500, loss = 0.6140\n",
      "Starting epoch 138 / 500\n",
      "t = 100, loss = 0.5577\n",
      "t = 200, loss = 0.6089\n",
      "t = 300, loss = 0.5686\n",
      "t = 400, loss = 0.5757\n",
      "t = 500, loss = 0.5890\n",
      "Starting epoch 139 / 500\n",
      "t = 100, loss = 0.5721\n",
      "t = 200, loss = 0.5906\n",
      "t = 300, loss = 0.5743\n",
      "t = 400, loss = 0.5863\n",
      "t = 500, loss = 0.5787\n",
      "Starting epoch 140 / 500\n",
      "t = 100, loss = 0.5814\n",
      "t = 200, loss = 0.5909\n",
      "t = 300, loss = 0.5689\n",
      "t = 400, loss = 0.5859\n",
      "t = 500, loss = 0.5732\n",
      "Starting epoch 141 / 500\n",
      "t = 100, loss = 0.5552\n",
      "t = 200, loss = 0.5770\n",
      "t = 300, loss = 0.5696\n",
      "t = 400, loss = 0.5691\n",
      "t = 500, loss = 0.5908\n",
      "Starting epoch 142 / 500\n",
      "t = 100, loss = 0.5681\n",
      "t = 200, loss = 0.6067\n",
      "t = 300, loss = 0.5705\n",
      "t = 400, loss = 0.5874\n",
      "t = 500, loss = 0.5667\n",
      "Starting epoch 143 / 500\n",
      "t = 100, loss = 0.5762\n",
      "t = 200, loss = 0.5843\n",
      "t = 300, loss = 0.5622\n",
      "t = 400, loss = 0.5810\n",
      "t = 500, loss = 0.5762\n",
      "Starting epoch 144 / 500\n",
      "t = 100, loss = 0.5751\n",
      "t = 200, loss = 0.5840\n",
      "t = 300, loss = 0.5868\n",
      "t = 400, loss = 0.5803\n",
      "t = 500, loss = 0.5729\n",
      "Starting epoch 145 / 500\n",
      "t = 100, loss = 0.5711\n",
      "t = 200, loss = 0.5912\n",
      "t = 300, loss = 0.5743\n",
      "t = 400, loss = 0.5664\n",
      "t = 500, loss = 0.5624\n",
      "Starting epoch 146 / 500\n",
      "t = 100, loss = 0.5727\n",
      "t = 200, loss = 0.5949\n",
      "t = 300, loss = 0.5680\n",
      "t = 400, loss = 0.6006\n",
      "t = 500, loss = 0.5827\n",
      "Starting epoch 147 / 500\n",
      "t = 100, loss = 0.5772\n",
      "t = 200, loss = 0.5804\n",
      "t = 300, loss = 0.5474\n",
      "t = 400, loss = 0.5806\n",
      "t = 500, loss = 0.5744\n",
      "Starting epoch 148 / 500\n",
      "t = 100, loss = 0.5801\n",
      "t = 200, loss = 0.5773\n",
      "t = 300, loss = 0.5693\n",
      "t = 400, loss = 0.5694\n",
      "t = 500, loss = 0.5753\n",
      "Starting epoch 149 / 500\n",
      "t = 100, loss = 0.5788\n",
      "t = 200, loss = 0.5747\n",
      "t = 300, loss = 0.5662\n",
      "t = 400, loss = 0.5801\n",
      "t = 500, loss = 0.5796\n",
      "Starting epoch 150 / 500\n",
      "t = 100, loss = 0.5594\n",
      "t = 200, loss = 0.5845\n",
      "t = 300, loss = 0.5631\n",
      "t = 400, loss = 0.5767\n",
      "t = 500, loss = 0.5593\n",
      "Starting epoch 151 / 500\n",
      "t = 100, loss = 0.5717\n",
      "t = 200, loss = 0.5826\n",
      "t = 300, loss = 0.5716\n",
      "t = 400, loss = 0.5723\n",
      "t = 500, loss = 0.5762\n",
      "Starting epoch 152 / 500\n",
      "t = 100, loss = 0.5642\n",
      "t = 200, loss = 0.5785\n",
      "t = 300, loss = 0.5605\n",
      "t = 400, loss = 0.5805\n",
      "t = 500, loss = 0.5738\n",
      "Starting epoch 153 / 500\n",
      "t = 100, loss = 0.5599\n",
      "t = 200, loss = 0.5672\n",
      "t = 300, loss = 0.5530\n",
      "t = 400, loss = 0.5692\n",
      "t = 500, loss = 0.5754\n",
      "Starting epoch 154 / 500\n",
      "t = 100, loss = 0.5673\n",
      "t = 200, loss = 0.5670\n",
      "t = 300, loss = 0.5725\n",
      "t = 400, loss = 0.5842\n",
      "t = 500, loss = 0.5759\n",
      "Starting epoch 155 / 500\n",
      "t = 100, loss = 0.5657\n",
      "t = 200, loss = 0.5777\n",
      "t = 300, loss = 0.5719\n",
      "t = 400, loss = 0.5807\n",
      "t = 500, loss = 0.5620\n",
      "Starting epoch 156 / 500\n",
      "t = 100, loss = 0.5669\n",
      "t = 200, loss = 0.5775\n",
      "t = 300, loss = 0.5619\n",
      "t = 400, loss = 0.5763\n",
      "t = 500, loss = 0.5633\n",
      "Starting epoch 157 / 500\n",
      "t = 100, loss = 0.5539\n",
      "t = 200, loss = 0.5678\n",
      "t = 300, loss = 0.5563\n",
      "t = 400, loss = 0.5741\n",
      "t = 500, loss = 0.5797\n",
      "Starting epoch 158 / 500\n",
      "t = 100, loss = 0.5588\n",
      "t = 200, loss = 0.5674\n",
      "t = 300, loss = 0.5509\n",
      "t = 400, loss = 0.5844\n",
      "t = 500, loss = 0.5680\n",
      "Starting epoch 159 / 500\n",
      "t = 100, loss = 0.5781\n",
      "t = 200, loss = 0.5761\n",
      "t = 300, loss = 0.5340\n",
      "t = 400, loss = 0.5752\n",
      "t = 500, loss = 0.5754\n",
      "Starting epoch 160 / 500\n",
      "t = 100, loss = 0.5594\n",
      "t = 200, loss = 0.5683\n",
      "t = 300, loss = 0.5587\n",
      "t = 400, loss = 0.5803\n",
      "t = 500, loss = 0.5710\n",
      "Starting epoch 161 / 500\n",
      "t = 100, loss = 0.5614\n",
      "t = 200, loss = 0.5823\n",
      "t = 300, loss = 0.5568\n",
      "t = 400, loss = 0.5829\n",
      "t = 500, loss = 0.5769\n",
      "Starting epoch 162 / 500\n",
      "t = 100, loss = 0.5613\n",
      "t = 200, loss = 0.5805\n",
      "t = 300, loss = 0.5580\n",
      "t = 400, loss = 0.5703\n",
      "t = 500, loss = 0.5658\n",
      "Starting epoch 163 / 500\n",
      "t = 100, loss = 0.5641\n",
      "t = 200, loss = 0.5738\n",
      "t = 300, loss = 0.5698\n",
      "t = 400, loss = 0.5781\n",
      "t = 500, loss = 0.5526\n",
      "Starting epoch 164 / 500\n",
      "t = 100, loss = 0.5594\n",
      "t = 200, loss = 0.5791\n",
      "t = 300, loss = 0.5536\n",
      "t = 400, loss = 0.5715\n",
      "t = 500, loss = 0.5802\n",
      "Starting epoch 165 / 500\n",
      "t = 100, loss = 0.5659\n",
      "t = 200, loss = 0.5755\n",
      "t = 300, loss = 0.5627\n",
      "t = 400, loss = 0.5727\n",
      "t = 500, loss = 0.5726\n",
      "Starting epoch 166 / 500\n",
      "t = 100, loss = 0.5549\n",
      "t = 200, loss = 0.5554\n",
      "t = 300, loss = 0.5592\n",
      "t = 400, loss = 0.5627\n",
      "t = 500, loss = 0.5570\n",
      "Starting epoch 167 / 500\n",
      "t = 100, loss = 0.5667\n",
      "t = 200, loss = 0.5814\n",
      "t = 300, loss = 0.5643\n",
      "t = 400, loss = 0.5683\n",
      "t = 500, loss = 0.5450\n",
      "Starting epoch 168 / 500\n",
      "t = 100, loss = 0.5635\n",
      "t = 200, loss = 0.5807\n",
      "t = 300, loss = 0.5777\n",
      "t = 400, loss = 0.5769\n",
      "t = 500, loss = 0.5599\n",
      "Starting epoch 169 / 500\n",
      "t = 100, loss = 0.5626\n",
      "t = 200, loss = 0.5656\n",
      "t = 300, loss = 0.5542\n",
      "t = 400, loss = 0.5768\n",
      "t = 500, loss = 0.5663\n",
      "Starting epoch 170 / 500\n",
      "t = 100, loss = 0.5592\n",
      "t = 200, loss = 0.5656\n",
      "t = 300, loss = 0.5539\n",
      "t = 400, loss = 0.5744\n",
      "t = 500, loss = 0.5695\n",
      "Starting epoch 171 / 500\n",
      "t = 100, loss = 0.5535\n",
      "t = 200, loss = 0.5848\n",
      "t = 300, loss = 0.5587\n",
      "t = 400, loss = 0.5721\n",
      "t = 500, loss = 0.5496\n",
      "Starting epoch 172 / 500\n",
      "t = 100, loss = 0.5592\n",
      "t = 200, loss = 0.5704\n",
      "t = 300, loss = 0.5629\n",
      "t = 400, loss = 0.5562\n",
      "t = 500, loss = 0.5527\n",
      "Starting epoch 173 / 500\n",
      "t = 100, loss = 0.5635\n",
      "t = 200, loss = 0.5608\n",
      "t = 300, loss = 0.5654\n",
      "t = 400, loss = 0.5574\n",
      "t = 500, loss = 0.5833\n",
      "Starting epoch 174 / 500\n",
      "t = 100, loss = 0.5624\n",
      "t = 200, loss = 0.5755\n",
      "t = 300, loss = 0.5526\n",
      "t = 400, loss = 0.5666\n",
      "t = 500, loss = 0.5631\n",
      "Starting epoch 175 / 500\n",
      "t = 100, loss = 0.5492\n",
      "t = 200, loss = 0.5710\n",
      "t = 300, loss = 0.5594\n",
      "t = 400, loss = 0.5538\n",
      "t = 500, loss = 0.5639\n",
      "Starting epoch 176 / 500\n",
      "t = 100, loss = 0.5532\n",
      "t = 200, loss = 0.5521\n",
      "t = 300, loss = 0.5477\n",
      "t = 400, loss = 0.5564\n",
      "t = 500, loss = 0.5537\n",
      "Starting epoch 177 / 500\n",
      "t = 100, loss = 0.5489\n",
      "t = 200, loss = 0.5657\n",
      "t = 300, loss = 0.5667\n",
      "t = 400, loss = 0.5572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 500, loss = 0.5634\n",
      "Starting epoch 178 / 500\n",
      "t = 100, loss = 0.5542\n",
      "t = 200, loss = 0.5530\n",
      "t = 300, loss = 0.5532\n",
      "t = 400, loss = 0.5589\n",
      "t = 500, loss = 0.5634\n",
      "Starting epoch 179 / 500\n",
      "t = 100, loss = 0.5584\n",
      "t = 200, loss = 0.5565\n",
      "t = 300, loss = 0.5452\n",
      "t = 400, loss = 0.5654\n",
      "t = 500, loss = 0.5622\n",
      "Starting epoch 180 / 500\n",
      "t = 100, loss = 0.5450\n",
      "t = 200, loss = 0.5711\n",
      "t = 300, loss = 0.5571\n",
      "t = 400, loss = 0.5824\n",
      "t = 500, loss = 0.5607\n",
      "Starting epoch 181 / 500\n",
      "t = 100, loss = 0.5506\n",
      "t = 200, loss = 0.5729\n",
      "t = 300, loss = 0.5538\n",
      "t = 400, loss = 0.5652\n",
      "t = 500, loss = 0.5657\n",
      "Starting epoch 182 / 500\n",
      "t = 100, loss = 0.5459\n",
      "t = 200, loss = 0.5750\n",
      "t = 300, loss = 0.5472\n",
      "t = 400, loss = 0.5617\n",
      "t = 500, loss = 0.5524\n",
      "Starting epoch 183 / 500\n",
      "t = 100, loss = 0.5410\n",
      "t = 200, loss = 0.5640\n",
      "t = 300, loss = 0.5534\n",
      "t = 400, loss = 0.5767\n",
      "t = 500, loss = 0.5641\n",
      "Starting epoch 184 / 500\n",
      "t = 100, loss = 0.5736\n",
      "t = 200, loss = 0.5567\n",
      "t = 300, loss = 0.5496\n",
      "t = 400, loss = 0.5557\n",
      "t = 500, loss = 0.5597\n",
      "Starting epoch 185 / 500\n",
      "t = 100, loss = 0.5638\n",
      "t = 200, loss = 0.5600\n",
      "t = 300, loss = 0.5621\n",
      "t = 400, loss = 0.5556\n",
      "t = 500, loss = 0.5468\n",
      "Starting epoch 186 / 500\n",
      "t = 100, loss = 0.5417\n",
      "t = 200, loss = 0.5828\n",
      "t = 300, loss = 0.5522\n",
      "t = 400, loss = 0.5629\n",
      "t = 500, loss = 0.5331\n",
      "Starting epoch 187 / 500\n",
      "t = 100, loss = 0.5423\n",
      "t = 200, loss = 0.5729\n",
      "t = 300, loss = 0.5481\n",
      "t = 400, loss = 0.5505\n",
      "t = 500, loss = 0.5617\n",
      "Starting epoch 188 / 500\n",
      "t = 100, loss = 0.5525\n",
      "t = 200, loss = 0.5740\n",
      "t = 300, loss = 0.5505\n",
      "t = 400, loss = 0.5668\n",
      "t = 500, loss = 0.5546\n",
      "Starting epoch 189 / 500\n",
      "t = 100, loss = 0.5391\n",
      "t = 200, loss = 0.5632\n",
      "t = 300, loss = 0.5511\n",
      "t = 400, loss = 0.5583\n",
      "t = 500, loss = 0.5527\n",
      "Starting epoch 190 / 500\n",
      "t = 100, loss = 0.5521\n",
      "t = 200, loss = 0.5735\n",
      "t = 300, loss = 0.5384\n",
      "t = 400, loss = 0.5626\n",
      "t = 500, loss = 0.5517\n",
      "Starting epoch 191 / 500\n",
      "t = 100, loss = 0.5419\n",
      "t = 200, loss = 0.5520\n",
      "t = 300, loss = 0.5479\n",
      "t = 400, loss = 0.5660\n",
      "t = 500, loss = 0.5461\n",
      "Starting epoch 192 / 500\n",
      "t = 100, loss = 0.5419\n",
      "t = 200, loss = 0.5616\n",
      "t = 300, loss = 0.5365\n",
      "t = 400, loss = 0.5609\n",
      "t = 500, loss = 0.5545\n",
      "Starting epoch 193 / 500\n",
      "t = 100, loss = 0.5535\n",
      "t = 200, loss = 0.5537\n",
      "t = 300, loss = 0.5475\n",
      "t = 400, loss = 0.5564\n",
      "t = 500, loss = 0.5491\n",
      "Starting epoch 194 / 500\n",
      "t = 100, loss = 0.5350\n",
      "t = 200, loss = 0.5491\n",
      "t = 300, loss = 0.5434\n",
      "t = 400, loss = 0.5710\n",
      "t = 500, loss = 0.5772\n",
      "Starting epoch 195 / 500\n",
      "t = 100, loss = 0.5516\n",
      "t = 200, loss = 0.5559\n",
      "t = 300, loss = 0.5459\n",
      "t = 400, loss = 0.5691\n",
      "t = 500, loss = 0.5562\n",
      "Starting epoch 196 / 500\n",
      "t = 100, loss = 0.5455\n",
      "t = 200, loss = 0.5553\n",
      "t = 300, loss = 0.5645\n",
      "t = 400, loss = 0.5573\n",
      "t = 500, loss = 0.5489\n",
      "Starting epoch 197 / 500\n",
      "t = 100, loss = 0.5476\n",
      "t = 200, loss = 0.5589\n",
      "t = 300, loss = 0.5292\n",
      "t = 400, loss = 0.5585\n",
      "t = 500, loss = 0.5426\n",
      "Starting epoch 198 / 500\n",
      "t = 100, loss = 0.5492\n",
      "t = 200, loss = 0.5536\n",
      "t = 300, loss = 0.5449\n",
      "t = 400, loss = 0.5801\n",
      "t = 500, loss = 0.5553\n",
      "Starting epoch 199 / 500\n",
      "t = 100, loss = 0.5498\n",
      "t = 200, loss = 0.5775\n",
      "t = 300, loss = 0.5496\n",
      "t = 400, loss = 0.5418\n",
      "t = 500, loss = 0.5529\n",
      "Starting epoch 200 / 500\n",
      "t = 100, loss = 0.5583\n",
      "t = 200, loss = 0.5649\n",
      "t = 300, loss = 0.5385\n",
      "t = 400, loss = 0.5508\n",
      "t = 500, loss = 0.5608\n",
      "Starting epoch 201 / 500\n",
      "t = 100, loss = 0.5177\n",
      "t = 200, loss = 0.5037\n",
      "t = 300, loss = 0.4834\n",
      "t = 400, loss = 0.4635\n",
      "t = 500, loss = 0.4492\n",
      "Starting epoch 202 / 500\n",
      "t = 100, loss = 0.4663\n",
      "t = 200, loss = 0.4729\n",
      "t = 300, loss = 0.4562\n",
      "t = 400, loss = 0.4582\n",
      "t = 500, loss = 0.4466\n",
      "Starting epoch 203 / 500\n",
      "t = 100, loss = 0.4500\n",
      "t = 200, loss = 0.4497\n",
      "t = 300, loss = 0.4359\n",
      "t = 400, loss = 0.4389\n",
      "t = 500, loss = 0.4249\n",
      "Starting epoch 204 / 500\n",
      "t = 100, loss = 0.4492\n",
      "t = 200, loss = 0.4457\n",
      "t = 300, loss = 0.4373\n",
      "t = 400, loss = 0.4386\n",
      "t = 500, loss = 0.4386\n",
      "Starting epoch 205 / 500\n",
      "t = 100, loss = 0.4338\n",
      "t = 200, loss = 0.4421\n",
      "t = 300, loss = 0.4373\n",
      "t = 400, loss = 0.4392\n",
      "t = 500, loss = 0.4334\n",
      "Starting epoch 206 / 500\n",
      "t = 100, loss = 0.4290\n",
      "t = 200, loss = 0.4363\n",
      "t = 300, loss = 0.4103\n",
      "t = 400, loss = 0.4291\n",
      "t = 500, loss = 0.4172\n",
      "Starting epoch 207 / 500\n",
      "t = 100, loss = 0.4277\n",
      "t = 200, loss = 0.4320\n",
      "t = 300, loss = 0.4149\n",
      "t = 400, loss = 0.4158\n",
      "t = 500, loss = 0.4258\n",
      "Starting epoch 208 / 500\n",
      "t = 100, loss = 0.4279\n",
      "t = 200, loss = 0.4235\n",
      "t = 300, loss = 0.4244\n",
      "t = 400, loss = 0.4160\n",
      "t = 500, loss = 0.4087\n",
      "Starting epoch 209 / 500\n",
      "t = 100, loss = 0.4184\n",
      "t = 200, loss = 0.4370\n",
      "t = 300, loss = 0.4031\n",
      "t = 400, loss = 0.4199\n",
      "t = 500, loss = 0.4203\n",
      "Starting epoch 210 / 500\n",
      "t = 100, loss = 0.4097\n",
      "t = 200, loss = 0.4232\n",
      "t = 300, loss = 0.4054\n",
      "t = 400, loss = 0.4056\n",
      "t = 500, loss = 0.4063\n",
      "Starting epoch 211 / 500\n",
      "t = 100, loss = 0.4280\n",
      "t = 200, loss = 0.4323\n",
      "t = 300, loss = 0.3957\n",
      "t = 400, loss = 0.4136\n",
      "t = 500, loss = 0.4015\n",
      "Starting epoch 212 / 500\n",
      "t = 100, loss = 0.4109\n",
      "t = 200, loss = 0.4058\n",
      "t = 300, loss = 0.4067\n",
      "t = 400, loss = 0.4088\n",
      "t = 500, loss = 0.3979\n",
      "Starting epoch 213 / 500\n",
      "t = 100, loss = 0.4201\n",
      "t = 200, loss = 0.4164\n",
      "t = 300, loss = 0.3946\n",
      "t = 400, loss = 0.4026\n",
      "t = 500, loss = 0.3969\n",
      "Starting epoch 214 / 500\n",
      "t = 100, loss = 0.4087\n",
      "t = 200, loss = 0.4178\n",
      "t = 300, loss = 0.3896\n",
      "t = 400, loss = 0.4077\n",
      "t = 500, loss = 0.4020\n",
      "Starting epoch 215 / 500\n",
      "t = 100, loss = 0.3957\n",
      "t = 200, loss = 0.4128\n",
      "t = 300, loss = 0.4050\n",
      "t = 400, loss = 0.3941\n",
      "t = 500, loss = 0.3941\n",
      "Starting epoch 216 / 500\n",
      "t = 100, loss = 0.4053\n",
      "t = 200, loss = 0.4082\n",
      "t = 300, loss = 0.3971\n",
      "t = 400, loss = 0.3936\n",
      "t = 500, loss = 0.3954\n",
      "Starting epoch 217 / 500\n",
      "t = 100, loss = 0.4055\n",
      "t = 200, loss = 0.4077\n",
      "t = 300, loss = 0.3943\n",
      "t = 400, loss = 0.3989\n",
      "t = 500, loss = 0.4010\n",
      "Starting epoch 218 / 500\n",
      "t = 100, loss = 0.4072\n",
      "t = 200, loss = 0.4033\n",
      "t = 300, loss = 0.4016\n",
      "t = 400, loss = 0.3995\n",
      "t = 500, loss = 0.3948\n",
      "Starting epoch 219 / 500\n",
      "t = 100, loss = 0.4154\n",
      "t = 200, loss = 0.4079\n",
      "t = 300, loss = 0.3833\n",
      "t = 400, loss = 0.3892\n",
      "t = 500, loss = 0.3870\n",
      "Starting epoch 220 / 500\n",
      "t = 100, loss = 0.4088\n",
      "t = 200, loss = 0.4132\n",
      "t = 300, loss = 0.3911\n",
      "t = 400, loss = 0.3948\n",
      "t = 500, loss = 0.4008\n",
      "Starting epoch 221 / 500\n",
      "t = 100, loss = 0.3912\n",
      "t = 200, loss = 0.3960\n",
      "t = 300, loss = 0.3824\n",
      "t = 400, loss = 0.3846\n",
      "t = 500, loss = 0.3939\n",
      "Starting epoch 222 / 500\n",
      "t = 100, loss = 0.3968\n",
      "t = 200, loss = 0.4105\n",
      "t = 300, loss = 0.3841\n",
      "t = 400, loss = 0.4130\n",
      "t = 500, loss = 0.3989\n",
      "Starting epoch 223 / 500\n",
      "t = 100, loss = 0.3991\n",
      "t = 200, loss = 0.4002\n",
      "t = 300, loss = 0.3837\n",
      "t = 400, loss = 0.3949\n",
      "t = 500, loss = 0.3847\n",
      "Starting epoch 224 / 500\n",
      "t = 100, loss = 0.3935\n",
      "t = 200, loss = 0.4019\n",
      "t = 300, loss = 0.3894\n",
      "t = 400, loss = 0.3945\n",
      "t = 500, loss = 0.3788\n",
      "Starting epoch 225 / 500\n",
      "t = 100, loss = 0.3997\n",
      "t = 200, loss = 0.3810\n",
      "t = 300, loss = 0.3940\n",
      "t = 400, loss = 0.3839\n",
      "t = 500, loss = 0.3799\n",
      "Starting epoch 226 / 500\n",
      "t = 100, loss = 0.3973\n",
      "t = 200, loss = 0.3893\n",
      "t = 300, loss = 0.3844\n",
      "t = 400, loss = 0.3874\n",
      "t = 500, loss = 0.3890\n",
      "Starting epoch 227 / 500\n",
      "t = 100, loss = 0.3766\n",
      "t = 200, loss = 0.4095\n",
      "t = 300, loss = 0.3748\n",
      "t = 400, loss = 0.3915\n",
      "t = 500, loss = 0.3923\n",
      "Starting epoch 228 / 500\n",
      "t = 100, loss = 0.3856\n",
      "t = 200, loss = 0.4010\n",
      "t = 300, loss = 0.3882\n",
      "t = 400, loss = 0.3800\n",
      "t = 500, loss = 0.3868\n",
      "Starting epoch 229 / 500\n",
      "t = 100, loss = 0.3692\n",
      "t = 200, loss = 0.3816\n",
      "t = 300, loss = 0.3687\n",
      "t = 400, loss = 0.3875\n",
      "t = 500, loss = 0.3879\n",
      "Starting epoch 230 / 500\n",
      "t = 100, loss = 0.4013\n",
      "t = 200, loss = 0.3909\n",
      "t = 300, loss = 0.3830\n",
      "t = 400, loss = 0.3880\n",
      "t = 500, loss = 0.3787\n",
      "Starting epoch 231 / 500\n",
      "t = 100, loss = 0.3810\n",
      "t = 200, loss = 0.3880\n",
      "t = 300, loss = 0.3783\n",
      "t = 400, loss = 0.3846\n",
      "t = 500, loss = 0.3910\n",
      "Starting epoch 232 / 500\n",
      "t = 100, loss = 0.3724\n",
      "t = 200, loss = 0.3821\n",
      "t = 300, loss = 0.3779\n",
      "t = 400, loss = 0.3900\n",
      "t = 500, loss = 0.3748\n",
      "Starting epoch 233 / 500\n",
      "t = 100, loss = 0.3839\n",
      "t = 200, loss = 0.3862\n",
      "t = 300, loss = 0.3685\n",
      "t = 400, loss = 0.3746\n",
      "t = 500, loss = 0.3829\n",
      "Starting epoch 234 / 500\n",
      "t = 100, loss = 0.3908\n",
      "t = 200, loss = 0.4006\n",
      "t = 300, loss = 0.3757\n",
      "t = 400, loss = 0.3987\n",
      "t = 500, loss = 0.3769\n",
      "Starting epoch 235 / 500\n",
      "t = 100, loss = 0.3802\n",
      "t = 200, loss = 0.3779\n",
      "t = 300, loss = 0.3737\n",
      "t = 400, loss = 0.3790\n",
      "t = 500, loss = 0.3815\n",
      "Starting epoch 236 / 500\n",
      "t = 100, loss = 0.3759\n",
      "t = 200, loss = 0.3759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 300, loss = 0.3781\n",
      "t = 400, loss = 0.3894\n",
      "t = 500, loss = 0.3611\n",
      "Starting epoch 237 / 500\n",
      "t = 100, loss = 0.3848\n",
      "t = 200, loss = 0.3985\n",
      "t = 300, loss = 0.3725\n",
      "t = 400, loss = 0.3839\n",
      "t = 500, loss = 0.3761\n",
      "Starting epoch 238 / 500\n",
      "t = 100, loss = 0.3821\n",
      "t = 200, loss = 0.3828\n",
      "t = 300, loss = 0.3785\n",
      "t = 400, loss = 0.3813\n",
      "t = 500, loss = 0.3551\n",
      "Starting epoch 239 / 500\n",
      "t = 100, loss = 0.3799\n",
      "t = 200, loss = 0.3822\n",
      "t = 300, loss = 0.3671\n",
      "t = 400, loss = 0.3813\n",
      "t = 500, loss = 0.3722\n",
      "Starting epoch 240 / 500\n",
      "t = 100, loss = 0.3865\n",
      "t = 200, loss = 0.3760\n",
      "t = 300, loss = 0.3687\n",
      "t = 400, loss = 0.3794\n",
      "t = 500, loss = 0.3844\n",
      "Starting epoch 241 / 500\n",
      "t = 100, loss = 0.3880\n",
      "t = 200, loss = 0.3846\n",
      "t = 300, loss = 0.3796\n",
      "t = 400, loss = 0.3659\n",
      "t = 500, loss = 0.3765\n",
      "Starting epoch 242 / 500\n",
      "t = 100, loss = 0.3859\n",
      "t = 200, loss = 0.3813\n",
      "t = 300, loss = 0.3569\n",
      "t = 400, loss = 0.3648\n",
      "t = 500, loss = 0.3826\n",
      "Starting epoch 243 / 500\n",
      "t = 100, loss = 0.3787\n",
      "t = 200, loss = 0.3789\n",
      "t = 300, loss = 0.3611\n",
      "t = 400, loss = 0.3743\n",
      "t = 500, loss = 0.3644\n",
      "Starting epoch 244 / 500\n",
      "t = 100, loss = 0.3716\n",
      "t = 200, loss = 0.3793\n",
      "t = 300, loss = 0.3701\n",
      "t = 400, loss = 0.3746\n",
      "t = 500, loss = 0.3698\n",
      "Starting epoch 245 / 500\n",
      "t = 100, loss = 0.3689\n",
      "t = 200, loss = 0.3852\n",
      "t = 300, loss = 0.3669\n",
      "t = 400, loss = 0.3773\n",
      "t = 500, loss = 0.3693\n",
      "Starting epoch 246 / 500\n",
      "t = 100, loss = 0.3710\n",
      "t = 200, loss = 0.3783\n",
      "t = 300, loss = 0.3704\n",
      "t = 400, loss = 0.3825\n",
      "t = 500, loss = 0.3672\n",
      "Starting epoch 247 / 500\n",
      "t = 100, loss = 0.3673\n",
      "t = 200, loss = 0.3669\n",
      "t = 300, loss = 0.3676\n",
      "t = 400, loss = 0.3757\n",
      "t = 500, loss = 0.3833\n",
      "Starting epoch 248 / 500\n",
      "t = 100, loss = 0.3607\n",
      "t = 200, loss = 0.3722\n",
      "t = 300, loss = 0.3804\n",
      "t = 400, loss = 0.3630\n",
      "t = 500, loss = 0.3647\n",
      "Starting epoch 249 / 500\n",
      "t = 100, loss = 0.3751\n",
      "t = 200, loss = 0.3726\n",
      "t = 300, loss = 0.3540\n",
      "t = 400, loss = 0.3750\n",
      "t = 500, loss = 0.3619\n",
      "Starting epoch 250 / 500\n",
      "t = 100, loss = 0.3726\n",
      "t = 200, loss = 0.3734\n",
      "t = 300, loss = 0.3528\n",
      "t = 400, loss = 0.3620\n",
      "t = 500, loss = 0.3814\n",
      "Starting epoch 251 / 500\n",
      "t = 100, loss = 0.3660\n",
      "t = 200, loss = 0.3779\n",
      "t = 300, loss = 0.3672\n",
      "t = 400, loss = 0.3736\n",
      "t = 500, loss = 0.3585\n",
      "Starting epoch 252 / 500\n",
      "t = 100, loss = 0.3638\n",
      "t = 200, loss = 0.3874\n",
      "t = 300, loss = 0.3648\n",
      "t = 400, loss = 0.3682\n",
      "t = 500, loss = 0.3679\n",
      "Starting epoch 253 / 500\n",
      "t = 100, loss = 0.3730\n",
      "t = 200, loss = 0.3706\n",
      "t = 300, loss = 0.3693\n",
      "t = 400, loss = 0.3744\n",
      "t = 500, loss = 0.3591\n",
      "Starting epoch 254 / 500\n",
      "t = 100, loss = 0.3587\n",
      "t = 200, loss = 0.3713\n",
      "t = 300, loss = 0.3600\n",
      "t = 400, loss = 0.3691\n",
      "t = 500, loss = 0.3710\n",
      "Starting epoch 255 / 500\n",
      "t = 100, loss = 0.3668\n",
      "t = 200, loss = 0.3667\n",
      "t = 300, loss = 0.3609\n",
      "t = 400, loss = 0.3713\n",
      "t = 500, loss = 0.3622\n",
      "Starting epoch 256 / 500\n",
      "t = 100, loss = 0.3739\n",
      "t = 200, loss = 0.3721\n",
      "t = 300, loss = 0.3570\n",
      "t = 400, loss = 0.3725\n",
      "t = 500, loss = 0.3554\n",
      "Starting epoch 257 / 500\n",
      "t = 100, loss = 0.3805\n",
      "t = 200, loss = 0.3587\n",
      "t = 300, loss = 0.3693\n",
      "t = 400, loss = 0.3501\n",
      "t = 500, loss = 0.3639\n",
      "Starting epoch 258 / 500\n",
      "t = 100, loss = 0.3668\n",
      "t = 200, loss = 0.3673\n",
      "t = 300, loss = 0.3588\n",
      "t = 400, loss = 0.3577\n",
      "t = 500, loss = 0.3546\n",
      "Starting epoch 259 / 500\n",
      "t = 100, loss = 0.3672\n",
      "t = 200, loss = 0.3750\n",
      "t = 300, loss = 0.3470\n",
      "t = 400, loss = 0.3655\n",
      "t = 500, loss = 0.3678\n",
      "Starting epoch 260 / 500\n",
      "t = 100, loss = 0.3629\n",
      "t = 200, loss = 0.3726\n",
      "t = 300, loss = 0.3759\n",
      "t = 400, loss = 0.3540\n",
      "t = 500, loss = 0.3623\n",
      "Starting epoch 261 / 500\n",
      "t = 100, loss = 0.3578\n",
      "t = 200, loss = 0.3631\n",
      "t = 300, loss = 0.3595\n",
      "t = 400, loss = 0.3802\n",
      "t = 500, loss = 0.3705\n",
      "Starting epoch 262 / 500\n",
      "t = 100, loss = 0.3626\n",
      "t = 200, loss = 0.3591\n",
      "t = 300, loss = 0.3499\n",
      "t = 400, loss = 0.3529\n",
      "t = 500, loss = 0.3604\n",
      "Starting epoch 263 / 500\n",
      "t = 100, loss = 0.3637\n",
      "t = 200, loss = 0.3542\n",
      "t = 300, loss = 0.3605\n",
      "t = 400, loss = 0.3662\n",
      "t = 500, loss = 0.3533\n",
      "Starting epoch 264 / 500\n",
      "t = 100, loss = 0.3565\n",
      "t = 200, loss = 0.3711\n",
      "t = 300, loss = 0.3588\n",
      "t = 400, loss = 0.3590\n",
      "t = 500, loss = 0.3597\n",
      "Starting epoch 265 / 500\n",
      "t = 100, loss = 0.3638\n",
      "t = 200, loss = 0.3689\n",
      "t = 300, loss = 0.3621\n",
      "t = 400, loss = 0.3731\n",
      "t = 500, loss = 0.3593\n",
      "Starting epoch 266 / 500\n",
      "t = 100, loss = 0.3514\n",
      "t = 200, loss = 0.3442\n",
      "t = 300, loss = 0.3541\n",
      "t = 400, loss = 0.3661\n",
      "t = 500, loss = 0.3532\n",
      "Starting epoch 267 / 500\n",
      "t = 100, loss = 0.3638\n",
      "t = 200, loss = 0.3739\n",
      "t = 300, loss = 0.3490\n",
      "t = 400, loss = 0.3563\n",
      "t = 500, loss = 0.3438\n",
      "Starting epoch 268 / 500\n",
      "t = 100, loss = 0.3625\n",
      "t = 200, loss = 0.3636\n",
      "t = 300, loss = 0.3652\n",
      "t = 400, loss = 0.3607\n",
      "t = 500, loss = 0.3621\n",
      "Starting epoch 269 / 500\n",
      "t = 100, loss = 0.3529\n",
      "t = 200, loss = 0.3606\n",
      "t = 300, loss = 0.3519\n",
      "t = 400, loss = 0.3599\n",
      "t = 500, loss = 0.3541\n",
      "Starting epoch 270 / 500\n",
      "t = 100, loss = 0.3805\n",
      "t = 200, loss = 0.3747\n",
      "t = 300, loss = 0.3618\n",
      "t = 400, loss = 0.3645\n",
      "t = 500, loss = 0.3617\n",
      "Starting epoch 271 / 500\n",
      "t = 100, loss = 0.3572\n",
      "t = 200, loss = 0.3486\n",
      "t = 300, loss = 0.3584\n",
      "t = 400, loss = 0.3750\n",
      "t = 500, loss = 0.3644\n",
      "Starting epoch 272 / 500\n",
      "t = 100, loss = 0.3727\n",
      "t = 200, loss = 0.3653\n",
      "t = 300, loss = 0.3555\n",
      "t = 400, loss = 0.3579\n",
      "t = 500, loss = 0.3547\n",
      "Starting epoch 273 / 500\n",
      "t = 100, loss = 0.3632\n",
      "t = 200, loss = 0.3647\n",
      "t = 300, loss = 0.3552\n",
      "t = 400, loss = 0.3685\n",
      "t = 500, loss = 0.3560\n",
      "Starting epoch 274 / 500\n",
      "t = 100, loss = 0.3834\n",
      "t = 200, loss = 0.3666\n",
      "t = 300, loss = 0.3575\n",
      "t = 400, loss = 0.3582\n",
      "t = 500, loss = 0.3559\n",
      "Starting epoch 275 / 500\n",
      "t = 100, loss = 0.3603\n",
      "t = 200, loss = 0.3638\n",
      "t = 300, loss = 0.3548\n",
      "t = 400, loss = 0.3582\n",
      "t = 500, loss = 0.3614\n",
      "Starting epoch 276 / 500\n",
      "t = 100, loss = 0.3526\n",
      "t = 200, loss = 0.3764\n",
      "t = 300, loss = 0.3617\n",
      "t = 400, loss = 0.3666\n",
      "t = 500, loss = 0.3612\n",
      "Starting epoch 277 / 500\n",
      "t = 100, loss = 0.3662\n",
      "t = 200, loss = 0.3665\n",
      "t = 300, loss = 0.3595\n",
      "t = 400, loss = 0.3676\n",
      "t = 500, loss = 0.3486\n",
      "Starting epoch 278 / 500\n",
      "t = 100, loss = 0.3520\n",
      "t = 200, loss = 0.3529\n",
      "t = 300, loss = 0.3585\n",
      "t = 400, loss = 0.3471\n",
      "t = 500, loss = 0.3592\n",
      "Starting epoch 279 / 500\n",
      "t = 100, loss = 0.3379\n",
      "t = 200, loss = 0.3687\n",
      "t = 300, loss = 0.3597\n",
      "t = 400, loss = 0.3493\n",
      "t = 500, loss = 0.3679\n",
      "Starting epoch 280 / 500\n",
      "t = 100, loss = 0.3577\n",
      "t = 200, loss = 0.3565\n",
      "t = 300, loss = 0.3463\n",
      "t = 400, loss = 0.3680\n",
      "t = 500, loss = 0.3520\n",
      "Starting epoch 281 / 500\n",
      "t = 100, loss = 0.3474\n",
      "t = 200, loss = 0.3590\n",
      "t = 300, loss = 0.3535\n",
      "t = 400, loss = 0.3543\n",
      "t = 500, loss = 0.3600\n",
      "Starting epoch 282 / 500\n",
      "t = 100, loss = 0.3500\n",
      "t = 200, loss = 0.3595\n",
      "t = 300, loss = 0.3561\n",
      "t = 400, loss = 0.3666\n",
      "t = 500, loss = 0.3699\n",
      "Starting epoch 283 / 500\n",
      "t = 100, loss = 0.3451\n",
      "t = 200, loss = 0.3672\n",
      "t = 300, loss = 0.3658\n",
      "t = 400, loss = 0.3539\n",
      "t = 500, loss = 0.3517\n",
      "Starting epoch 284 / 500\n",
      "t = 100, loss = 0.3443\n",
      "t = 200, loss = 0.3737\n",
      "t = 300, loss = 0.3500\n",
      "t = 400, loss = 0.3571\n",
      "t = 500, loss = 0.3601\n",
      "Starting epoch 285 / 500\n",
      "t = 100, loss = 0.3641\n",
      "t = 200, loss = 0.3566\n",
      "t = 300, loss = 0.3358\n",
      "t = 400, loss = 0.3600\n",
      "t = 500, loss = 0.3532\n",
      "Starting epoch 286 / 500\n",
      "t = 100, loss = 0.3569\n",
      "t = 200, loss = 0.3640\n",
      "t = 300, loss = 0.3603\n",
      "t = 400, loss = 0.3547\n",
      "t = 500, loss = 0.3561\n",
      "Starting epoch 287 / 500\n",
      "t = 100, loss = 0.3493\n",
      "t = 200, loss = 0.3616\n",
      "t = 300, loss = 0.3636\n",
      "t = 400, loss = 0.3413\n",
      "t = 500, loss = 0.3596\n",
      "Starting epoch 288 / 500\n",
      "t = 100, loss = 0.3409\n",
      "t = 200, loss = 0.3683\n",
      "t = 300, loss = 0.3498\n",
      "t = 400, loss = 0.3551\n",
      "t = 500, loss = 0.3447\n",
      "Starting epoch 289 / 500\n",
      "t = 100, loss = 0.3500\n",
      "t = 200, loss = 0.3529\n",
      "t = 300, loss = 0.3457\n",
      "t = 400, loss = 0.3611\n",
      "t = 500, loss = 0.3553\n",
      "Starting epoch 290 / 500\n",
      "t = 100, loss = 0.3453\n",
      "t = 200, loss = 0.3619\n",
      "t = 300, loss = 0.3516\n",
      "t = 400, loss = 0.3527\n",
      "t = 500, loss = 0.3660\n",
      "Starting epoch 291 / 500\n",
      "t = 100, loss = 0.3476\n",
      "t = 200, loss = 0.3666\n",
      "t = 300, loss = 0.3456\n",
      "t = 400, loss = 0.3391\n",
      "t = 500, loss = 0.3578\n",
      "Starting epoch 292 / 500\n",
      "t = 100, loss = 0.3490\n",
      "t = 200, loss = 0.3615\n",
      "t = 300, loss = 0.3432\n",
      "t = 400, loss = 0.3571\n",
      "t = 500, loss = 0.3475\n",
      "Starting epoch 293 / 500\n",
      "t = 100, loss = 0.3480\n",
      "t = 200, loss = 0.3595\n",
      "t = 300, loss = 0.3628\n",
      "t = 400, loss = 0.3392\n",
      "t = 500, loss = 0.3492\n",
      "Starting epoch 294 / 500\n",
      "t = 100, loss = 0.3619\n",
      "t = 200, loss = 0.3579\n",
      "t = 300, loss = 0.3438\n",
      "t = 400, loss = 0.3562\n",
      "t = 500, loss = 0.3411\n",
      "Starting epoch 295 / 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 100, loss = 0.3660\n",
      "t = 200, loss = 0.3620\n",
      "t = 300, loss = 0.3442\n",
      "t = 400, loss = 0.3595\n",
      "t = 500, loss = 0.3521\n",
      "Starting epoch 296 / 500\n",
      "t = 100, loss = 0.3507\n",
      "t = 200, loss = 0.3482\n",
      "t = 300, loss = 0.3523\n",
      "t = 400, loss = 0.3629\n",
      "t = 500, loss = 0.3484\n",
      "Starting epoch 297 / 500\n",
      "t = 100, loss = 0.3616\n",
      "t = 200, loss = 0.3520\n",
      "t = 300, loss = 0.3456\n",
      "t = 400, loss = 0.3544\n",
      "t = 500, loss = 0.3473\n",
      "Starting epoch 298 / 500\n",
      "t = 100, loss = 0.3535\n",
      "t = 200, loss = 0.3489\n",
      "t = 300, loss = 0.3436\n",
      "t = 400, loss = 0.3435\n",
      "t = 500, loss = 0.3544\n",
      "Starting epoch 299 / 500\n",
      "t = 100, loss = 0.3587\n",
      "t = 200, loss = 0.3531\n",
      "t = 300, loss = 0.3509\n",
      "t = 400, loss = 0.3504\n",
      "t = 500, loss = 0.3501\n",
      "Starting epoch 300 / 500\n",
      "t = 100, loss = 0.3474\n",
      "t = 200, loss = 0.3552\n",
      "t = 300, loss = 0.3508\n",
      "t = 400, loss = 0.3428\n",
      "t = 500, loss = 0.3560\n",
      "Starting epoch 301 / 500\n",
      "t = 100, loss = 0.3528\n",
      "t = 200, loss = 0.3610\n",
      "t = 300, loss = 0.3316\n",
      "t = 400, loss = 0.3299\n",
      "t = 500, loss = 0.3370\n",
      "Starting epoch 302 / 500\n",
      "t = 100, loss = 0.3424\n",
      "t = 200, loss = 0.3481\n",
      "t = 300, loss = 0.3257\n",
      "t = 400, loss = 0.3438\n",
      "t = 500, loss = 0.3313\n",
      "Starting epoch 303 / 500\n",
      "t = 100, loss = 0.3376\n",
      "t = 200, loss = 0.3391\n",
      "t = 300, loss = 0.3238\n",
      "t = 400, loss = 0.3371\n",
      "t = 500, loss = 0.3375\n",
      "Starting epoch 304 / 500\n",
      "t = 100, loss = 0.3245\n",
      "t = 200, loss = 0.3382\n",
      "t = 300, loss = 0.3298\n",
      "t = 400, loss = 0.3272\n",
      "t = 500, loss = 0.3199\n",
      "Starting epoch 305 / 500\n",
      "t = 100, loss = 0.3249\n",
      "t = 200, loss = 0.3354\n",
      "t = 300, loss = 0.3245\n",
      "t = 400, loss = 0.3346\n",
      "t = 500, loss = 0.3323\n",
      "Starting epoch 306 / 500\n",
      "t = 100, loss = 0.3217\n",
      "t = 200, loss = 0.3420\n",
      "t = 300, loss = 0.3240\n",
      "t = 400, loss = 0.3247\n",
      "t = 500, loss = 0.3312\n",
      "Starting epoch 307 / 500\n",
      "t = 100, loss = 0.3348\n",
      "t = 200, loss = 0.3229\n",
      "t = 300, loss = 0.3335\n",
      "t = 400, loss = 0.3340\n",
      "t = 500, loss = 0.3354\n",
      "Starting epoch 308 / 500\n",
      "t = 100, loss = 0.3254\n",
      "t = 200, loss = 0.3295\n",
      "t = 300, loss = 0.3246\n",
      "t = 400, loss = 0.3346\n",
      "t = 500, loss = 0.3264\n",
      "Starting epoch 309 / 500\n",
      "t = 100, loss = 0.3201\n",
      "t = 200, loss = 0.3373\n",
      "t = 300, loss = 0.3202\n",
      "t = 400, loss = 0.3332\n",
      "t = 500, loss = 0.3283\n",
      "Starting epoch 310 / 500\n",
      "t = 100, loss = 0.3234\n",
      "t = 200, loss = 0.3303\n",
      "t = 300, loss = 0.3257\n",
      "t = 400, loss = 0.3237\n",
      "t = 500, loss = 0.3366\n",
      "Starting epoch 311 / 500\n",
      "t = 100, loss = 0.3337\n",
      "t = 200, loss = 0.3203\n",
      "t = 300, loss = 0.3289\n",
      "t = 400, loss = 0.3207\n",
      "t = 500, loss = 0.3092\n",
      "Starting epoch 312 / 500\n",
      "t = 100, loss = 0.3200\n",
      "t = 200, loss = 0.3217\n",
      "t = 300, loss = 0.3103\n",
      "t = 400, loss = 0.3129\n",
      "t = 500, loss = 0.3265\n",
      "Starting epoch 313 / 500\n",
      "t = 100, loss = 0.3256\n",
      "t = 200, loss = 0.3359\n",
      "t = 300, loss = 0.3227\n",
      "t = 400, loss = 0.3165\n",
      "t = 500, loss = 0.3203\n",
      "Starting epoch 314 / 500\n",
      "t = 100, loss = 0.3190\n",
      "t = 200, loss = 0.3195\n",
      "t = 300, loss = 0.3250\n",
      "t = 400, loss = 0.3233\n",
      "t = 500, loss = 0.3353\n",
      "Starting epoch 315 / 500\n",
      "t = 100, loss = 0.3207\n",
      "t = 200, loss = 0.3305\n",
      "t = 300, loss = 0.3296\n",
      "t = 400, loss = 0.3385\n",
      "t = 500, loss = 0.3324\n",
      "Starting epoch 316 / 500\n",
      "t = 100, loss = 0.3208\n",
      "t = 200, loss = 0.3231\n",
      "t = 300, loss = 0.3238\n",
      "t = 400, loss = 0.3265\n",
      "t = 500, loss = 0.3243\n",
      "Starting epoch 317 / 500\n",
      "t = 100, loss = 0.3163\n",
      "t = 200, loss = 0.3325\n",
      "t = 300, loss = 0.3093\n",
      "t = 400, loss = 0.3229\n",
      "t = 500, loss = 0.3198\n",
      "Starting epoch 318 / 500\n",
      "t = 100, loss = 0.3196\n",
      "t = 200, loss = 0.3343\n",
      "t = 300, loss = 0.3214\n",
      "t = 400, loss = 0.3121\n",
      "t = 500, loss = 0.3207\n",
      "Starting epoch 319 / 500\n",
      "t = 100, loss = 0.3126\n",
      "t = 200, loss = 0.3230\n",
      "t = 300, loss = 0.3238\n",
      "t = 400, loss = 0.3247\n",
      "t = 500, loss = 0.3208\n",
      "Starting epoch 320 / 500\n",
      "t = 100, loss = 0.3227\n",
      "t = 200, loss = 0.3227\n",
      "t = 300, loss = 0.3207\n",
      "t = 400, loss = 0.3320\n",
      "t = 500, loss = 0.3202\n",
      "Starting epoch 321 / 500\n",
      "t = 100, loss = 0.3059\n",
      "t = 200, loss = 0.3182\n",
      "t = 300, loss = 0.3224\n",
      "t = 400, loss = 0.3098\n",
      "t = 500, loss = 0.3210\n",
      "Starting epoch 322 / 500\n",
      "t = 100, loss = 0.3294\n",
      "t = 200, loss = 0.3177\n",
      "t = 300, loss = 0.3158\n",
      "t = 400, loss = 0.3303\n",
      "t = 500, loss = 0.3203\n",
      "Starting epoch 323 / 500\n",
      "t = 100, loss = 0.3200\n",
      "t = 200, loss = 0.3167\n",
      "t = 300, loss = 0.3167\n",
      "t = 400, loss = 0.3112\n",
      "t = 500, loss = 0.3278\n",
      "Starting epoch 324 / 500\n",
      "t = 100, loss = 0.3123\n",
      "t = 200, loss = 0.3338\n",
      "t = 300, loss = 0.3258\n",
      "t = 400, loss = 0.3176\n",
      "t = 500, loss = 0.3169\n",
      "Starting epoch 325 / 500\n",
      "t = 100, loss = 0.3146\n",
      "t = 200, loss = 0.3223\n",
      "t = 300, loss = 0.3196\n",
      "t = 400, loss = 0.3169\n",
      "t = 500, loss = 0.3393\n",
      "Starting epoch 326 / 500\n",
      "t = 100, loss = 0.3259\n",
      "t = 200, loss = 0.3296\n",
      "t = 300, loss = 0.3075\n",
      "t = 400, loss = 0.3217\n",
      "t = 500, loss = 0.3225\n",
      "Starting epoch 327 / 500\n",
      "t = 100, loss = 0.3187\n",
      "t = 200, loss = 0.3370\n",
      "t = 300, loss = 0.3114\n",
      "t = 400, loss = 0.3319\n",
      "t = 500, loss = 0.3256\n",
      "Starting epoch 328 / 500\n",
      "t = 100, loss = 0.3106\n",
      "t = 200, loss = 0.3258\n",
      "t = 300, loss = 0.3294\n",
      "t = 400, loss = 0.3196\n",
      "t = 500, loss = 0.3299\n",
      "Starting epoch 329 / 500\n",
      "t = 100, loss = 0.3175\n",
      "t = 200, loss = 0.3236\n",
      "t = 300, loss = 0.3085\n",
      "t = 400, loss = 0.3190\n",
      "t = 500, loss = 0.3176\n",
      "Starting epoch 330 / 500\n",
      "t = 100, loss = 0.3095\n",
      "t = 200, loss = 0.3319\n",
      "t = 300, loss = 0.3185\n",
      "t = 400, loss = 0.3206\n",
      "t = 500, loss = 0.3255\n",
      "Starting epoch 331 / 500\n",
      "t = 100, loss = 0.3186\n",
      "t = 200, loss = 0.3323\n",
      "t = 300, loss = 0.3126\n",
      "t = 400, loss = 0.3113\n",
      "t = 500, loss = 0.3205\n",
      "Starting epoch 332 / 500\n",
      "t = 100, loss = 0.3243\n",
      "t = 200, loss = 0.3282\n",
      "t = 300, loss = 0.3238\n",
      "t = 400, loss = 0.3248\n",
      "t = 500, loss = 0.3322\n",
      "Starting epoch 333 / 500\n",
      "t = 100, loss = 0.3283\n",
      "t = 200, loss = 0.3219\n",
      "t = 300, loss = 0.3067\n",
      "t = 400, loss = 0.3187\n",
      "t = 500, loss = 0.3302\n",
      "Starting epoch 334 / 500\n",
      "t = 100, loss = 0.3191\n",
      "t = 200, loss = 0.3286\n",
      "t = 300, loss = 0.3109\n",
      "t = 400, loss = 0.3166\n",
      "t = 500, loss = 0.3186\n",
      "Starting epoch 335 / 500\n",
      "t = 100, loss = 0.3140\n",
      "t = 200, loss = 0.3342\n",
      "t = 300, loss = 0.3220\n",
      "t = 400, loss = 0.3188\n",
      "t = 500, loss = 0.3282\n",
      "Starting epoch 336 / 500\n",
      "t = 100, loss = 0.3209\n",
      "t = 200, loss = 0.3263\n",
      "t = 300, loss = 0.3123\n",
      "t = 400, loss = 0.3100\n",
      "t = 500, loss = 0.3167\n",
      "Starting epoch 337 / 500\n",
      "t = 100, loss = 0.3272\n",
      "t = 200, loss = 0.3329\n",
      "t = 300, loss = 0.3121\n",
      "t = 400, loss = 0.3195\n",
      "t = 500, loss = 0.3102\n",
      "Starting epoch 338 / 500\n",
      "t = 100, loss = 0.3238\n",
      "t = 200, loss = 0.3163\n",
      "t = 300, loss = 0.3188\n",
      "t = 400, loss = 0.3229\n",
      "t = 500, loss = 0.3152\n",
      "Starting epoch 339 / 500\n",
      "t = 100, loss = 0.3284\n",
      "t = 200, loss = 0.3240\n",
      "t = 300, loss = 0.3214\n",
      "t = 400, loss = 0.3153\n",
      "t = 500, loss = 0.3266\n",
      "Starting epoch 340 / 500\n",
      "t = 100, loss = 0.3200\n",
      "t = 200, loss = 0.3186\n",
      "t = 300, loss = 0.3279\n",
      "t = 400, loss = 0.3185\n",
      "t = 500, loss = 0.3062\n",
      "Starting epoch 341 / 500\n",
      "t = 100, loss = 0.3117\n",
      "t = 200, loss = 0.3141\n",
      "t = 300, loss = 0.3169\n",
      "t = 400, loss = 0.3206\n",
      "t = 500, loss = 0.3161\n",
      "Starting epoch 342 / 500\n",
      "t = 100, loss = 0.3119\n",
      "t = 200, loss = 0.3257\n",
      "t = 300, loss = 0.3189\n",
      "t = 400, loss = 0.3173\n",
      "t = 500, loss = 0.3041\n",
      "Starting epoch 343 / 500\n",
      "t = 100, loss = 0.3127\n",
      "t = 200, loss = 0.3372\n",
      "t = 300, loss = 0.3211\n",
      "t = 400, loss = 0.3113\n",
      "t = 500, loss = 0.3242\n",
      "Starting epoch 344 / 500\n",
      "t = 100, loss = 0.3126\n",
      "t = 200, loss = 0.3225\n",
      "t = 300, loss = 0.3105\n",
      "t = 400, loss = 0.3186\n",
      "t = 500, loss = 0.3097\n",
      "Starting epoch 345 / 500\n",
      "t = 100, loss = 0.3216\n",
      "t = 200, loss = 0.3221\n",
      "t = 300, loss = 0.3114\n",
      "t = 400, loss = 0.3230\n",
      "t = 500, loss = 0.3121\n",
      "Starting epoch 346 / 500\n",
      "t = 100, loss = 0.3257\n",
      "t = 200, loss = 0.3307\n",
      "t = 300, loss = 0.3095\n",
      "t = 400, loss = 0.3184\n",
      "t = 500, loss = 0.3175\n",
      "Starting epoch 347 / 500\n",
      "t = 100, loss = 0.3273\n",
      "t = 200, loss = 0.3170\n",
      "t = 300, loss = 0.3093\n",
      "t = 400, loss = 0.3075\n",
      "t = 500, loss = 0.3249\n",
      "Starting epoch 348 / 500\n",
      "t = 100, loss = 0.3186\n",
      "t = 200, loss = 0.3107\n",
      "t = 300, loss = 0.3157\n",
      "t = 400, loss = 0.3270\n",
      "t = 500, loss = 0.3183\n",
      "Starting epoch 349 / 500\n",
      "t = 100, loss = 0.3152\n",
      "t = 200, loss = 0.3275\n",
      "t = 300, loss = 0.3306\n",
      "t = 400, loss = 0.3154\n",
      "t = 500, loss = 0.3138\n",
      "Starting epoch 350 / 500\n",
      "t = 100, loss = 0.3152\n",
      "t = 200, loss = 0.3268\n",
      "t = 300, loss = 0.3095\n",
      "t = 400, loss = 0.3208\n",
      "t = 500, loss = 0.3256\n",
      "Starting epoch 351 / 500\n",
      "t = 100, loss = 0.3203\n",
      "t = 200, loss = 0.3195\n",
      "t = 300, loss = 0.3155\n",
      "t = 400, loss = 0.3136\n",
      "t = 500, loss = 0.3216\n",
      "Starting epoch 352 / 500\n",
      "t = 100, loss = 0.3134\n",
      "t = 200, loss = 0.3260\n",
      "t = 300, loss = 0.3203\n",
      "t = 400, loss = 0.3251\n",
      "t = 500, loss = 0.3241\n",
      "Starting epoch 353 / 500\n",
      "t = 100, loss = 0.3200\n",
      "t = 200, loss = 0.3261\n",
      "t = 300, loss = 0.3086\n",
      "t = 400, loss = 0.3175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 500, loss = 0.3119\n",
      "Starting epoch 354 / 500\n",
      "t = 100, loss = 0.3174\n",
      "t = 200, loss = 0.3312\n",
      "t = 300, loss = 0.3112\n",
      "t = 400, loss = 0.3214\n",
      "t = 500, loss = 0.3169\n",
      "Starting epoch 355 / 500\n",
      "t = 100, loss = 0.3238\n",
      "t = 200, loss = 0.3209\n",
      "t = 300, loss = 0.3037\n",
      "t = 400, loss = 0.3272\n",
      "t = 500, loss = 0.3255\n",
      "Starting epoch 356 / 500\n",
      "t = 100, loss = 0.3163\n",
      "t = 200, loss = 0.3250\n",
      "t = 300, loss = 0.3158\n",
      "t = 400, loss = 0.3227\n",
      "t = 500, loss = 0.3219\n",
      "Starting epoch 357 / 500\n",
      "t = 100, loss = 0.3233\n",
      "t = 200, loss = 0.3219\n",
      "t = 300, loss = 0.3150\n",
      "t = 400, loss = 0.3069\n",
      "t = 500, loss = 0.3036\n",
      "Starting epoch 358 / 500\n",
      "t = 100, loss = 0.3212\n",
      "t = 200, loss = 0.3253\n",
      "t = 300, loss = 0.3108\n",
      "t = 400, loss = 0.3286\n",
      "t = 500, loss = 0.3235\n",
      "Starting epoch 359 / 500\n",
      "t = 100, loss = 0.3163\n",
      "t = 200, loss = 0.3283\n",
      "t = 300, loss = 0.3290\n",
      "t = 400, loss = 0.3199\n",
      "t = 500, loss = 0.3122\n",
      "Starting epoch 360 / 500\n",
      "t = 100, loss = 0.3112\n",
      "t = 200, loss = 0.3235\n",
      "t = 300, loss = 0.3200\n",
      "t = 400, loss = 0.3184\n",
      "t = 500, loss = 0.3159\n",
      "Starting epoch 361 / 500\n",
      "t = 100, loss = 0.3166\n",
      "t = 200, loss = 0.3127\n",
      "t = 300, loss = 0.3051\n",
      "t = 400, loss = 0.3124\n",
      "t = 500, loss = 0.3189\n",
      "Starting epoch 362 / 500\n",
      "t = 100, loss = 0.3089\n",
      "t = 200, loss = 0.3253\n",
      "t = 300, loss = 0.3071\n",
      "t = 400, loss = 0.3152\n",
      "t = 500, loss = 0.3182\n",
      "Starting epoch 363 / 500\n",
      "t = 100, loss = 0.3078\n",
      "t = 200, loss = 0.3219\n",
      "t = 300, loss = 0.3072\n",
      "t = 400, loss = 0.3195\n",
      "t = 500, loss = 0.3229\n",
      "Starting epoch 364 / 500\n",
      "t = 100, loss = 0.3145\n",
      "t = 200, loss = 0.3199\n",
      "t = 300, loss = 0.3077\n",
      "t = 400, loss = 0.3275\n",
      "t = 500, loss = 0.3148\n",
      "Starting epoch 365 / 500\n",
      "t = 100, loss = 0.3258\n",
      "t = 200, loss = 0.3165\n",
      "t = 300, loss = 0.3186\n",
      "t = 400, loss = 0.3029\n",
      "t = 500, loss = 0.3097\n",
      "Starting epoch 366 / 500\n",
      "t = 100, loss = 0.3185\n",
      "t = 200, loss = 0.3147\n",
      "t = 300, loss = 0.3151\n",
      "t = 400, loss = 0.3054\n",
      "t = 500, loss = 0.3145\n",
      "Starting epoch 367 / 500\n",
      "t = 100, loss = 0.3115\n",
      "t = 200, loss = 0.3091\n",
      "t = 300, loss = 0.3084\n",
      "t = 400, loss = 0.3138\n",
      "t = 500, loss = 0.3179\n",
      "Starting epoch 368 / 500\n",
      "t = 100, loss = 0.3097\n",
      "t = 200, loss = 0.3204\n",
      "t = 300, loss = 0.3161\n",
      "t = 400, loss = 0.3188\n",
      "t = 500, loss = 0.3251\n",
      "Starting epoch 369 / 500\n",
      "t = 100, loss = 0.3138\n",
      "t = 200, loss = 0.3148\n",
      "t = 300, loss = 0.3071\n",
      "t = 400, loss = 0.3258\n",
      "t = 500, loss = 0.3168\n",
      "Starting epoch 370 / 500\n",
      "t = 100, loss = 0.3229\n",
      "t = 200, loss = 0.3207\n",
      "t = 300, loss = 0.3166\n",
      "t = 400, loss = 0.3140\n",
      "t = 500, loss = 0.3283\n",
      "Starting epoch 371 / 500\n",
      "t = 100, loss = 0.3161\n",
      "t = 200, loss = 0.3288\n",
      "t = 300, loss = 0.3138\n",
      "t = 400, loss = 0.3158\n",
      "t = 500, loss = 0.3277\n",
      "Starting epoch 372 / 500\n",
      "t = 100, loss = 0.3194\n",
      "t = 200, loss = 0.3165\n",
      "t = 300, loss = 0.3253\n",
      "t = 400, loss = 0.3205\n",
      "t = 500, loss = 0.3067\n",
      "Starting epoch 373 / 500\n",
      "t = 100, loss = 0.3216\n",
      "t = 200, loss = 0.3188\n",
      "t = 300, loss = 0.2990\n",
      "t = 400, loss = 0.3241\n",
      "t = 500, loss = 0.3154\n",
      "Starting epoch 374 / 500\n",
      "t = 100, loss = 0.3190\n",
      "t = 200, loss = 0.3274\n",
      "t = 300, loss = 0.3059\n",
      "t = 400, loss = 0.3142\n",
      "t = 500, loss = 0.3135\n",
      "Starting epoch 375 / 500\n",
      "t = 100, loss = 0.3078\n",
      "t = 200, loss = 0.3216\n",
      "t = 300, loss = 0.3153\n",
      "t = 400, loss = 0.3239\n",
      "t = 500, loss = 0.3103\n",
      "Starting epoch 376 / 500\n",
      "t = 100, loss = 0.3178\n",
      "t = 200, loss = 0.3264\n",
      "t = 300, loss = 0.3143\n",
      "t = 400, loss = 0.3201\n",
      "t = 500, loss = 0.2999\n",
      "Starting epoch 377 / 500\n",
      "t = 100, loss = 0.3082\n",
      "t = 200, loss = 0.3209\n",
      "t = 300, loss = 0.3195\n",
      "t = 400, loss = 0.3171\n",
      "t = 500, loss = 0.3095\n",
      "Starting epoch 378 / 500\n",
      "t = 100, loss = 0.3238\n",
      "t = 200, loss = 0.3211\n",
      "t = 300, loss = 0.3159\n",
      "t = 400, loss = 0.3116\n",
      "t = 500, loss = 0.3219\n",
      "Starting epoch 379 / 500\n",
      "t = 100, loss = 0.3091\n",
      "t = 200, loss = 0.3192\n",
      "t = 300, loss = 0.3113\n",
      "t = 400, loss = 0.3100\n",
      "t = 500, loss = 0.3230\n",
      "Starting epoch 380 / 500\n",
      "t = 100, loss = 0.3187\n",
      "t = 200, loss = 0.3216\n",
      "t = 300, loss = 0.3097\n",
      "t = 400, loss = 0.3193\n",
      "t = 500, loss = 0.3127\n",
      "Starting epoch 381 / 500\n",
      "t = 100, loss = 0.3321\n",
      "t = 200, loss = 0.3228\n",
      "t = 300, loss = 0.3105\n",
      "t = 400, loss = 0.3182\n",
      "t = 500, loss = 0.3101\n",
      "Starting epoch 382 / 500\n",
      "t = 100, loss = 0.3087\n",
      "t = 200, loss = 0.3105\n",
      "t = 300, loss = 0.3243\n",
      "t = 400, loss = 0.3290\n",
      "t = 500, loss = 0.3260\n",
      "Starting epoch 383 / 500\n",
      "t = 100, loss = 0.3144\n",
      "t = 200, loss = 0.3213\n",
      "t = 300, loss = 0.3100\n",
      "t = 400, loss = 0.3060\n",
      "t = 500, loss = 0.3074\n",
      "Starting epoch 384 / 500\n",
      "t = 100, loss = 0.3187\n",
      "t = 200, loss = 0.3109\n",
      "t = 300, loss = 0.3025\n",
      "t = 400, loss = 0.3143\n",
      "t = 500, loss = 0.3164\n",
      "Starting epoch 385 / 500\n",
      "t = 100, loss = 0.3037\n",
      "t = 200, loss = 0.3315\n",
      "t = 300, loss = 0.3194\n",
      "t = 400, loss = 0.3029\n",
      "t = 500, loss = 0.3054\n",
      "Starting epoch 386 / 500\n",
      "t = 100, loss = 0.3048\n",
      "t = 200, loss = 0.3310\n",
      "t = 300, loss = 0.3282\n",
      "t = 400, loss = 0.3158\n",
      "t = 500, loss = 0.3071\n",
      "Starting epoch 387 / 500\n",
      "t = 100, loss = 0.3200\n",
      "t = 200, loss = 0.3148\n",
      "t = 300, loss = 0.3159\n",
      "t = 400, loss = 0.3114\n",
      "t = 500, loss = 0.3267\n",
      "Starting epoch 388 / 500\n",
      "t = 100, loss = 0.3118\n",
      "t = 200, loss = 0.3161\n",
      "t = 300, loss = 0.3135\n",
      "t = 400, loss = 0.3176\n",
      "t = 500, loss = 0.3119\n",
      "Starting epoch 389 / 500\n",
      "t = 100, loss = 0.3077\n",
      "t = 200, loss = 0.3204\n",
      "t = 300, loss = 0.3111\n",
      "t = 400, loss = 0.3049\n",
      "t = 500, loss = 0.3074\n",
      "Starting epoch 390 / 500\n",
      "t = 100, loss = 0.3180\n",
      "t = 200, loss = 0.3027\n",
      "t = 300, loss = 0.3162\n",
      "t = 400, loss = 0.3147\n",
      "t = 500, loss = 0.3101\n",
      "Starting epoch 391 / 500\n",
      "t = 100, loss = 0.3062\n",
      "t = 200, loss = 0.3230\n",
      "t = 300, loss = 0.3135\n",
      "t = 400, loss = 0.3157\n",
      "t = 500, loss = 0.3157\n",
      "Starting epoch 392 / 500\n",
      "t = 100, loss = 0.3207\n",
      "t = 200, loss = 0.3100\n",
      "t = 300, loss = 0.3038\n",
      "t = 400, loss = 0.3108\n",
      "t = 500, loss = 0.3138\n",
      "Starting epoch 393 / 500\n",
      "t = 100, loss = 0.3236\n",
      "t = 200, loss = 0.3026\n",
      "t = 300, loss = 0.3219\n",
      "t = 400, loss = 0.3035\n",
      "t = 500, loss = 0.3187\n",
      "Starting epoch 394 / 500\n",
      "t = 100, loss = 0.3216\n",
      "t = 200, loss = 0.3133\n",
      "t = 300, loss = 0.3202\n",
      "t = 400, loss = 0.3114\n",
      "t = 500, loss = 0.3109\n",
      "Starting epoch 395 / 500\n",
      "t = 100, loss = 0.3365\n",
      "t = 200, loss = 0.3164\n",
      "t = 300, loss = 0.3078\n",
      "t = 400, loss = 0.3146\n",
      "t = 500, loss = 0.3077\n",
      "Starting epoch 396 / 500\n",
      "t = 100, loss = 0.3246\n",
      "t = 200, loss = 0.3060\n",
      "t = 300, loss = 0.3332\n",
      "t = 400, loss = 0.3165\n",
      "t = 500, loss = 0.3135\n",
      "Starting epoch 397 / 500\n",
      "t = 100, loss = 0.3081\n",
      "t = 200, loss = 0.3111\n",
      "t = 300, loss = 0.3128\n",
      "t = 400, loss = 0.3168\n",
      "t = 500, loss = 0.3076\n",
      "Starting epoch 398 / 500\n",
      "t = 100, loss = 0.3207\n",
      "t = 200, loss = 0.3214\n",
      "t = 300, loss = 0.3008\n",
      "t = 400, loss = 0.3173\n",
      "t = 500, loss = 0.3059\n",
      "Starting epoch 399 / 500\n",
      "t = 100, loss = 0.3055\n",
      "t = 200, loss = 0.3077\n",
      "t = 300, loss = 0.3186\n",
      "t = 400, loss = 0.2989\n",
      "t = 500, loss = 0.3083\n",
      "Starting epoch 400 / 500\n",
      "t = 100, loss = 0.3111\n",
      "t = 200, loss = 0.3129\n",
      "t = 300, loss = 0.3076\n",
      "t = 400, loss = 0.3146\n",
      "t = 500, loss = 0.3088\n",
      "Starting epoch 401 / 500\n",
      "t = 100, loss = 0.3075\n",
      "t = 200, loss = 0.3181\n",
      "t = 300, loss = 0.3022\n",
      "t = 400, loss = 0.3204\n",
      "t = 500, loss = 0.3071\n",
      "Starting epoch 402 / 500\n",
      "t = 100, loss = 0.3078\n",
      "t = 200, loss = 0.3183\n",
      "t = 300, loss = 0.2989\n",
      "t = 400, loss = 0.3111\n",
      "t = 500, loss = 0.3084\n",
      "Starting epoch 403 / 500\n",
      "t = 100, loss = 0.3168\n",
      "t = 200, loss = 0.3063\n",
      "t = 300, loss = 0.3113\n",
      "t = 400, loss = 0.3286\n",
      "t = 500, loss = 0.3155\n",
      "Starting epoch 404 / 500\n",
      "t = 100, loss = 0.3072\n",
      "t = 200, loss = 0.3057\n",
      "t = 300, loss = 0.3100\n",
      "t = 400, loss = 0.3061\n",
      "t = 500, loss = 0.3104\n",
      "Starting epoch 405 / 500\n",
      "t = 100, loss = 0.3136\n",
      "t = 200, loss = 0.3189\n",
      "t = 300, loss = 0.3091\n",
      "t = 400, loss = 0.3039\n",
      "t = 500, loss = 0.2836\n",
      "Starting epoch 406 / 500\n",
      "t = 100, loss = 0.3176\n",
      "t = 200, loss = 0.3182\n",
      "t = 300, loss = 0.3011\n",
      "t = 400, loss = 0.3113\n",
      "t = 500, loss = 0.3155\n",
      "Starting epoch 407 / 500\n",
      "t = 100, loss = 0.3142\n",
      "t = 200, loss = 0.3218\n",
      "t = 300, loss = 0.3129\n",
      "t = 400, loss = 0.3167\n",
      "t = 500, loss = 0.3107\n",
      "Starting epoch 408 / 500\n",
      "t = 100, loss = 0.3149\n",
      "t = 200, loss = 0.3198\n",
      "t = 300, loss = 0.3079\n",
      "t = 400, loss = 0.2956\n",
      "t = 500, loss = 0.3284\n",
      "Starting epoch 409 / 500\n",
      "t = 100, loss = 0.3079\n",
      "t = 200, loss = 0.3076\n",
      "t = 300, loss = 0.3041\n",
      "t = 400, loss = 0.3132\n",
      "t = 500, loss = 0.3086\n",
      "Starting epoch 410 / 500\n",
      "t = 100, loss = 0.3121\n",
      "t = 200, loss = 0.3222\n",
      "t = 300, loss = 0.2971\n",
      "t = 400, loss = 0.3217\n",
      "t = 500, loss = 0.3142\n",
      "Starting epoch 411 / 500\n",
      "t = 100, loss = 0.3061\n",
      "t = 200, loss = 0.3029\n",
      "t = 300, loss = 0.3095\n",
      "t = 400, loss = 0.3156\n",
      "t = 500, loss = 0.3031\n",
      "Starting epoch 412 / 500\n",
      "t = 100, loss = 0.3208\n",
      "t = 200, loss = 0.3141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 300, loss = 0.3051\n",
      "t = 400, loss = 0.3191\n",
      "t = 500, loss = 0.3132\n",
      "Starting epoch 413 / 500\n",
      "t = 100, loss = 0.3108\n",
      "t = 200, loss = 0.3159\n",
      "t = 300, loss = 0.3067\n",
      "t = 400, loss = 0.3122\n",
      "t = 500, loss = 0.2989\n",
      "Starting epoch 414 / 500\n",
      "t = 100, loss = 0.3101\n",
      "t = 200, loss = 0.3184\n",
      "t = 300, loss = 0.3046\n",
      "t = 400, loss = 0.3167\n",
      "t = 500, loss = 0.3152\n",
      "Starting epoch 415 / 500\n",
      "t = 100, loss = 0.2945\n",
      "t = 200, loss = 0.2980\n",
      "t = 300, loss = 0.3051\n",
      "t = 400, loss = 0.3172\n",
      "t = 500, loss = 0.3053\n",
      "Starting epoch 416 / 500\n",
      "t = 100, loss = 0.3230\n",
      "t = 200, loss = 0.3184\n",
      "t = 300, loss = 0.3171\n",
      "t = 400, loss = 0.3128\n",
      "t = 500, loss = 0.3005\n",
      "Starting epoch 417 / 500\n",
      "t = 100, loss = 0.2997\n",
      "t = 200, loss = 0.3071\n",
      "t = 300, loss = 0.3170\n",
      "t = 400, loss = 0.3093\n",
      "t = 500, loss = 0.3093\n",
      "Starting epoch 418 / 500\n",
      "t = 100, loss = 0.3050\n",
      "t = 200, loss = 0.3188\n",
      "t = 300, loss = 0.3142\n",
      "t = 400, loss = 0.3189\n",
      "t = 500, loss = 0.2993\n",
      "Starting epoch 419 / 500\n",
      "t = 100, loss = 0.3205\n",
      "t = 200, loss = 0.3280\n",
      "t = 300, loss = 0.3155\n",
      "t = 400, loss = 0.3115\n",
      "t = 500, loss = 0.3067\n",
      "Starting epoch 420 / 500\n",
      "t = 100, loss = 0.3110\n",
      "t = 200, loss = 0.3207\n",
      "t = 300, loss = 0.3029\n",
      "t = 400, loss = 0.3160\n",
      "t = 500, loss = 0.3135\n",
      "Starting epoch 421 / 500\n",
      "t = 100, loss = 0.3188\n",
      "t = 200, loss = 0.3177\n",
      "t = 300, loss = 0.3174\n",
      "t = 400, loss = 0.3175\n",
      "t = 500, loss = 0.3204\n",
      "Starting epoch 422 / 500\n",
      "t = 100, loss = 0.3051\n",
      "t = 200, loss = 0.3056\n",
      "t = 300, loss = 0.3057\n",
      "t = 400, loss = 0.2991\n",
      "t = 500, loss = 0.3015\n",
      "Starting epoch 423 / 500\n",
      "t = 100, loss = 0.3076\n",
      "t = 200, loss = 0.3177\n",
      "t = 300, loss = 0.3059\n",
      "t = 400, loss = 0.3038\n",
      "t = 500, loss = 0.3071\n",
      "Starting epoch 424 / 500\n",
      "t = 100, loss = 0.3018\n",
      "t = 200, loss = 0.3113\n",
      "t = 300, loss = 0.3055\n",
      "t = 400, loss = 0.3075\n",
      "t = 500, loss = 0.3223\n",
      "Starting epoch 425 / 500\n",
      "t = 100, loss = 0.3171\n",
      "t = 200, loss = 0.3024\n",
      "t = 300, loss = 0.3047\n",
      "t = 400, loss = 0.3186\n",
      "t = 500, loss = 0.3071\n",
      "Starting epoch 426 / 500\n",
      "t = 100, loss = 0.3173\n",
      "t = 200, loss = 0.3098\n",
      "t = 300, loss = 0.3097\n",
      "t = 400, loss = 0.3065\n",
      "t = 500, loss = 0.3091\n",
      "Starting epoch 427 / 500\n",
      "t = 100, loss = 0.3093\n",
      "t = 200, loss = 0.3169\n",
      "t = 300, loss = 0.2967\n",
      "t = 400, loss = 0.3156\n",
      "t = 500, loss = 0.3027\n",
      "Starting epoch 428 / 500\n",
      "t = 100, loss = 0.2988\n",
      "t = 200, loss = 0.2974\n",
      "t = 300, loss = 0.3023\n",
      "t = 400, loss = 0.3066\n",
      "t = 500, loss = 0.3059\n",
      "Starting epoch 429 / 500\n",
      "t = 100, loss = 0.3151\n",
      "t = 200, loss = 0.3078\n",
      "t = 300, loss = 0.3055\n",
      "t = 400, loss = 0.3033\n",
      "t = 500, loss = 0.3088\n",
      "Starting epoch 430 / 500\n",
      "t = 100, loss = 0.3130\n",
      "t = 200, loss = 0.3129\n",
      "t = 300, loss = 0.3055\n",
      "t = 400, loss = 0.3136\n",
      "t = 500, loss = 0.3088\n",
      "Starting epoch 431 / 500\n",
      "t = 100, loss = 0.3133\n",
      "t = 200, loss = 0.3067\n",
      "t = 300, loss = 0.3083\n",
      "t = 400, loss = 0.3106\n",
      "t = 500, loss = 0.3030\n",
      "Starting epoch 432 / 500\n",
      "t = 100, loss = 0.3166\n",
      "t = 200, loss = 0.3120\n",
      "t = 300, loss = 0.3009\n",
      "t = 400, loss = 0.3030\n",
      "t = 500, loss = 0.3043\n",
      "Starting epoch 433 / 500\n",
      "t = 100, loss = 0.3112\n",
      "t = 200, loss = 0.3172\n",
      "t = 300, loss = 0.3063\n",
      "t = 400, loss = 0.3130\n",
      "t = 500, loss = 0.3050\n",
      "Starting epoch 434 / 500\n",
      "t = 100, loss = 0.3041\n",
      "t = 200, loss = 0.3097\n",
      "t = 300, loss = 0.2862\n",
      "t = 400, loss = 0.3214\n",
      "t = 500, loss = 0.3060\n",
      "Starting epoch 435 / 500\n",
      "t = 100, loss = 0.3177\n",
      "t = 200, loss = 0.3179\n",
      "t = 300, loss = 0.3028\n",
      "t = 400, loss = 0.3090\n",
      "t = 500, loss = 0.3033\n",
      "Starting epoch 436 / 500\n",
      "t = 100, loss = 0.3107\n",
      "t = 200, loss = 0.3097\n",
      "t = 300, loss = 0.2988\n",
      "t = 400, loss = 0.3014\n",
      "t = 500, loss = 0.3114\n",
      "Starting epoch 437 / 500\n",
      "t = 100, loss = 0.3134\n",
      "t = 200, loss = 0.3118\n",
      "t = 300, loss = 0.3118\n",
      "t = 400, loss = 0.3197\n",
      "t = 500, loss = 0.3099\n",
      "Starting epoch 438 / 500\n",
      "t = 100, loss = 0.3110\n",
      "t = 200, loss = 0.3190\n",
      "t = 300, loss = 0.3026\n",
      "t = 400, loss = 0.3068\n",
      "t = 500, loss = 0.2990\n",
      "Starting epoch 439 / 500\n",
      "t = 100, loss = 0.3128\n",
      "t = 200, loss = 0.3021\n",
      "t = 300, loss = 0.3018\n",
      "t = 400, loss = 0.3165\n",
      "t = 500, loss = 0.3107\n",
      "Starting epoch 440 / 500\n",
      "t = 100, loss = 0.3177\n",
      "t = 200, loss = 0.3231\n",
      "t = 300, loss = 0.3041\n",
      "t = 400, loss = 0.3120\n",
      "t = 500, loss = 0.3054\n",
      "Starting epoch 441 / 500\n",
      "t = 100, loss = 0.3110\n",
      "t = 200, loss = 0.3180\n",
      "t = 300, loss = 0.3114\n",
      "t = 400, loss = 0.3188\n",
      "t = 500, loss = 0.3035\n",
      "Starting epoch 442 / 500\n",
      "t = 100, loss = 0.3091\n",
      "t = 200, loss = 0.3135\n",
      "t = 300, loss = 0.3200\n",
      "t = 400, loss = 0.3054\n",
      "t = 500, loss = 0.2976\n",
      "Starting epoch 443 / 500\n",
      "t = 100, loss = 0.3152\n",
      "t = 200, loss = 0.3135\n",
      "t = 300, loss = 0.3025\n",
      "t = 400, loss = 0.3061\n",
      "t = 500, loss = 0.3150\n",
      "Starting epoch 444 / 500\n",
      "t = 100, loss = 0.3218\n",
      "t = 200, loss = 0.3175\n",
      "t = 300, loss = 0.3198\n",
      "t = 400, loss = 0.3104\n",
      "t = 500, loss = 0.2963\n",
      "Starting epoch 445 / 500\n",
      "t = 100, loss = 0.3101\n",
      "t = 200, loss = 0.3156\n",
      "t = 300, loss = 0.3042\n",
      "t = 400, loss = 0.3155\n",
      "t = 500, loss = 0.2969\n",
      "Starting epoch 446 / 500\n",
      "t = 100, loss = 0.3099\n",
      "t = 200, loss = 0.3109\n",
      "t = 300, loss = 0.2948\n",
      "t = 400, loss = 0.3166\n",
      "t = 500, loss = 0.2977\n",
      "Starting epoch 447 / 500\n",
      "t = 100, loss = 0.3047\n",
      "t = 200, loss = 0.3105\n",
      "t = 300, loss = 0.2984\n",
      "t = 400, loss = 0.3133\n",
      "t = 500, loss = 0.3063\n",
      "Starting epoch 448 / 500\n",
      "t = 100, loss = 0.3068\n",
      "t = 200, loss = 0.3045\n",
      "t = 300, loss = 0.2979\n",
      "t = 400, loss = 0.2989\n",
      "t = 500, loss = 0.3050\n",
      "Starting epoch 449 / 500\n",
      "t = 100, loss = 0.2999\n",
      "t = 200, loss = 0.3066\n",
      "t = 300, loss = 0.3022\n",
      "t = 400, loss = 0.3158\n",
      "t = 500, loss = 0.3116\n",
      "Starting epoch 450 / 500\n",
      "t = 100, loss = 0.3043\n",
      "t = 200, loss = 0.3081\n",
      "t = 300, loss = 0.3054\n",
      "t = 400, loss = 0.3054\n",
      "t = 500, loss = 0.3104\n",
      "Starting epoch 451 / 500\n",
      "t = 100, loss = 0.3136\n",
      "t = 200, loss = 0.2961\n",
      "t = 300, loss = 0.3090\n",
      "t = 400, loss = 0.3176\n",
      "t = 500, loss = 0.3109\n",
      "Starting epoch 452 / 500\n",
      "t = 100, loss = 0.3004\n",
      "t = 200, loss = 0.3054\n",
      "t = 300, loss = 0.2958\n",
      "t = 400, loss = 0.3081\n",
      "t = 500, loss = 0.3143\n",
      "Starting epoch 453 / 500\n",
      "t = 100, loss = 0.3035\n",
      "t = 200, loss = 0.3185\n",
      "t = 300, loss = 0.3066\n",
      "t = 400, loss = 0.3054\n",
      "t = 500, loss = 0.3192\n",
      "Starting epoch 454 / 500\n",
      "t = 100, loss = 0.3122\n",
      "t = 200, loss = 0.3169\n",
      "t = 300, loss = 0.3081\n",
      "t = 400, loss = 0.3005\n",
      "t = 500, loss = 0.3108\n",
      "Starting epoch 455 / 500\n",
      "t = 100, loss = 0.3236\n",
      "t = 200, loss = 0.3222\n",
      "t = 300, loss = 0.3127\n",
      "t = 400, loss = 0.3229\n",
      "t = 500, loss = 0.3138\n",
      "Starting epoch 456 / 500\n",
      "t = 100, loss = 0.3036\n",
      "t = 200, loss = 0.3111\n",
      "t = 300, loss = 0.3050\n",
      "t = 400, loss = 0.3033\n",
      "t = 500, loss = 0.3038\n",
      "Starting epoch 457 / 500\n",
      "t = 100, loss = 0.3147\n",
      "t = 200, loss = 0.3145\n",
      "t = 300, loss = 0.3064\n",
      "t = 400, loss = 0.3066\n",
      "t = 500, loss = 0.3025\n",
      "Starting epoch 458 / 500\n",
      "t = 100, loss = 0.3166\n",
      "t = 200, loss = 0.3112\n",
      "t = 300, loss = 0.3132\n",
      "t = 400, loss = 0.3071\n",
      "t = 500, loss = 0.3195\n",
      "Starting epoch 459 / 500\n",
      "t = 100, loss = 0.3077\n",
      "t = 200, loss = 0.3100\n",
      "t = 300, loss = 0.3019\n",
      "t = 400, loss = 0.3303\n",
      "t = 500, loss = 0.3194\n",
      "Starting epoch 460 / 500\n",
      "t = 100, loss = 0.3092\n",
      "t = 200, loss = 0.3001\n",
      "t = 300, loss = 0.3108\n",
      "t = 400, loss = 0.3047\n",
      "t = 500, loss = 0.3104\n",
      "Starting epoch 461 / 500\n",
      "t = 100, loss = 0.3029\n",
      "t = 200, loss = 0.3081\n",
      "t = 300, loss = 0.3123\n",
      "t = 400, loss = 0.3186\n",
      "t = 500, loss = 0.3146\n",
      "Starting epoch 462 / 500\n",
      "t = 100, loss = 0.2963\n",
      "t = 200, loss = 0.2984\n",
      "t = 300, loss = 0.3199\n",
      "t = 400, loss = 0.3169\n",
      "t = 500, loss = 0.3140\n",
      "Starting epoch 463 / 500\n",
      "t = 100, loss = 0.3108\n",
      "t = 200, loss = 0.3092\n",
      "t = 300, loss = 0.3082\n",
      "t = 400, loss = 0.3085\n",
      "t = 500, loss = 0.3075\n",
      "Starting epoch 464 / 500\n",
      "t = 100, loss = 0.3097\n",
      "t = 200, loss = 0.3065\n",
      "t = 300, loss = 0.3101\n",
      "t = 400, loss = 0.2978\n",
      "t = 500, loss = 0.2924\n",
      "Starting epoch 465 / 500\n",
      "t = 100, loss = 0.3160\n",
      "t = 200, loss = 0.3083\n",
      "t = 300, loss = 0.3073\n",
      "t = 400, loss = 0.3055\n",
      "t = 500, loss = 0.3095\n",
      "Starting epoch 466 / 500\n",
      "t = 100, loss = 0.3231\n",
      "t = 200, loss = 0.3159\n",
      "t = 300, loss = 0.3090\n",
      "t = 400, loss = 0.3029\n",
      "t = 500, loss = 0.3045\n",
      "Starting epoch 467 / 500\n",
      "t = 100, loss = 0.3037\n",
      "t = 200, loss = 0.3119\n",
      "t = 300, loss = 0.3100\n",
      "t = 400, loss = 0.3078\n",
      "t = 500, loss = 0.3177\n",
      "Starting epoch 468 / 500\n",
      "t = 100, loss = 0.3128\n",
      "t = 200, loss = 0.3122\n",
      "t = 300, loss = 0.3014\n",
      "t = 400, loss = 0.3160\n",
      "t = 500, loss = 0.3180\n",
      "Starting epoch 469 / 500\n",
      "t = 100, loss = 0.3134\n",
      "t = 200, loss = 0.3090\n",
      "t = 300, loss = 0.2992\n",
      "t = 400, loss = 0.3030\n",
      "t = 500, loss = 0.3162\n",
      "Starting epoch 470 / 500\n",
      "t = 100, loss = 0.3120\n",
      "t = 200, loss = 0.3147\n",
      "t = 300, loss = 0.3202\n",
      "t = 400, loss = 0.3032\n",
      "t = 500, loss = 0.3104\n",
      "Starting epoch 471 / 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 100, loss = 0.3051\n",
      "t = 200, loss = 0.3049\n",
      "t = 300, loss = 0.3113\n",
      "t = 400, loss = 0.3064\n",
      "t = 500, loss = 0.3020\n",
      "Starting epoch 472 / 500\n",
      "t = 100, loss = 0.3121\n",
      "t = 200, loss = 0.3151\n",
      "t = 300, loss = 0.2957\n",
      "t = 400, loss = 0.2975\n",
      "t = 500, loss = 0.3034\n",
      "Starting epoch 473 / 500\n",
      "t = 100, loss = 0.3094\n",
      "t = 200, loss = 0.3232\n",
      "t = 300, loss = 0.3048\n",
      "t = 400, loss = 0.2974\n",
      "t = 500, loss = 0.3123\n",
      "Starting epoch 474 / 500\n",
      "t = 100, loss = 0.3035\n",
      "t = 200, loss = 0.3279\n",
      "t = 300, loss = 0.3039\n",
      "t = 400, loss = 0.3000\n",
      "t = 500, loss = 0.3093\n",
      "Starting epoch 475 / 500\n",
      "t = 100, loss = 0.3125\n",
      "t = 200, loss = 0.3184\n",
      "t = 300, loss = 0.3129\n",
      "t = 400, loss = 0.3043\n",
      "t = 500, loss = 0.3085\n",
      "Starting epoch 476 / 500\n",
      "t = 100, loss = 0.3143\n",
      "t = 200, loss = 0.3168\n",
      "t = 300, loss = 0.3007\n",
      "t = 400, loss = 0.3092\n",
      "t = 500, loss = 0.3050\n",
      "Starting epoch 477 / 500\n",
      "t = 100, loss = 0.3223\n",
      "t = 200, loss = 0.3099\n",
      "t = 300, loss = 0.3079\n",
      "t = 400, loss = 0.3183\n",
      "t = 500, loss = 0.3096\n",
      "Starting epoch 478 / 500\n",
      "t = 100, loss = 0.3013\n",
      "t = 200, loss = 0.3151\n",
      "t = 300, loss = 0.3101\n",
      "t = 400, loss = 0.3104\n",
      "t = 500, loss = 0.3034\n",
      "Starting epoch 479 / 500\n",
      "t = 100, loss = 0.3133\n",
      "t = 200, loss = 0.3157\n",
      "t = 300, loss = 0.3096\n",
      "t = 400, loss = 0.3140\n",
      "t = 500, loss = 0.3050\n",
      "Starting epoch 480 / 500\n",
      "t = 100, loss = 0.3033\n",
      "t = 200, loss = 0.3234\n",
      "t = 300, loss = 0.2930\n",
      "t = 400, loss = 0.3123\n",
      "t = 500, loss = 0.2994\n",
      "Starting epoch 481 / 500\n",
      "t = 100, loss = 0.2936\n",
      "t = 200, loss = 0.3101\n",
      "t = 300, loss = 0.3027\n",
      "t = 400, loss = 0.3173\n",
      "t = 500, loss = 0.3178\n",
      "Starting epoch 482 / 500\n",
      "t = 100, loss = 0.3106\n",
      "t = 200, loss = 0.3089\n",
      "t = 300, loss = 0.3028\n",
      "t = 400, loss = 0.3097\n",
      "t = 500, loss = 0.2930\n",
      "Starting epoch 483 / 500\n",
      "t = 100, loss = 0.3095\n",
      "t = 200, loss = 0.3214\n",
      "t = 300, loss = 0.3053\n",
      "t = 400, loss = 0.3044\n",
      "t = 500, loss = 0.2993\n",
      "Starting epoch 484 / 500\n",
      "t = 100, loss = 0.3086\n",
      "t = 200, loss = 0.3115\n",
      "t = 300, loss = 0.3106\n",
      "t = 400, loss = 0.3162\n",
      "t = 500, loss = 0.3034\n",
      "Starting epoch 485 / 500\n",
      "t = 100, loss = 0.3180\n",
      "t = 200, loss = 0.3026\n",
      "t = 300, loss = 0.3117\n",
      "t = 400, loss = 0.2977\n",
      "t = 500, loss = 0.3119\n",
      "Starting epoch 486 / 500\n",
      "t = 100, loss = 0.3025\n",
      "t = 200, loss = 0.3188\n",
      "t = 300, loss = 0.3101\n",
      "t = 400, loss = 0.3026\n",
      "t = 500, loss = 0.3167\n",
      "Starting epoch 487 / 500\n",
      "t = 100, loss = 0.3149\n",
      "t = 200, loss = 0.3090\n",
      "t = 300, loss = 0.3042\n",
      "t = 400, loss = 0.3142\n",
      "t = 500, loss = 0.3026\n",
      "Starting epoch 488 / 500\n",
      "t = 100, loss = 0.3090\n",
      "t = 200, loss = 0.3131\n",
      "t = 300, loss = 0.3114\n",
      "t = 400, loss = 0.3143\n",
      "t = 500, loss = 0.3028\n",
      "Starting epoch 489 / 500\n",
      "t = 100, loss = 0.3009\n",
      "t = 200, loss = 0.3085\n",
      "t = 300, loss = 0.3042\n",
      "t = 400, loss = 0.3090\n",
      "t = 500, loss = 0.3095\n",
      "Starting epoch 490 / 500\n",
      "t = 100, loss = 0.3227\n",
      "t = 200, loss = 0.3111\n",
      "t = 300, loss = 0.3122\n",
      "t = 400, loss = 0.3025\n",
      "t = 500, loss = 0.3076\n",
      "Starting epoch 491 / 500\n",
      "t = 100, loss = 0.3068\n",
      "t = 200, loss = 0.3130\n",
      "t = 300, loss = 0.3019\n",
      "t = 400, loss = 0.3116\n",
      "t = 500, loss = 0.2965\n",
      "Starting epoch 492 / 500\n",
      "t = 100, loss = 0.3034\n",
      "t = 200, loss = 0.3098\n",
      "t = 300, loss = 0.3073\n",
      "t = 400, loss = 0.3140\n",
      "t = 500, loss = 0.3000\n",
      "Starting epoch 493 / 500\n",
      "t = 100, loss = 0.3011\n",
      "t = 200, loss = 0.3107\n",
      "t = 300, loss = 0.3030\n",
      "t = 400, loss = 0.3082\n",
      "t = 500, loss = 0.3081\n",
      "Starting epoch 494 / 500\n",
      "t = 100, loss = 0.2901\n",
      "t = 200, loss = 0.3118\n",
      "t = 300, loss = 0.3227\n",
      "t = 400, loss = 0.2969\n",
      "t = 500, loss = 0.2993\n",
      "Starting epoch 495 / 500\n",
      "t = 100, loss = 0.3106\n",
      "t = 200, loss = 0.3107\n",
      "t = 300, loss = 0.3115\n",
      "t = 400, loss = 0.3058\n",
      "t = 500, loss = 0.3105\n",
      "Starting epoch 496 / 500\n",
      "t = 100, loss = 0.3181\n",
      "t = 200, loss = 0.3163\n",
      "t = 300, loss = 0.3048\n",
      "t = 400, loss = 0.3061\n",
      "t = 500, loss = 0.3049\n",
      "Starting epoch 497 / 500\n",
      "t = 100, loss = 0.3044\n",
      "t = 200, loss = 0.3144\n",
      "t = 300, loss = 0.3087\n",
      "t = 400, loss = 0.3185\n",
      "t = 500, loss = 0.3117\n",
      "Starting epoch 498 / 500\n",
      "t = 100, loss = 0.3003\n",
      "t = 200, loss = 0.3001\n",
      "t = 300, loss = 0.3032\n",
      "t = 400, loss = 0.3053\n",
      "t = 500, loss = 0.2928\n",
      "Starting epoch 499 / 500\n",
      "t = 100, loss = 0.3065\n",
      "t = 200, loss = 0.3002\n",
      "t = 300, loss = 0.2965\n",
      "t = 400, loss = 0.3150\n",
      "t = 500, loss = 0.2945\n",
      "Starting epoch 500 / 500\n",
      "t = 100, loss = 0.2999\n",
      "t = 200, loss = 0.3102\n",
      "t = 300, loss = 0.3092\n",
      "t = 400, loss = 0.3170\n",
      "t = 500, loss = 0.3108\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFEREJKRQEBGRkEJBRERCCgUREQn9f+sgGsjQ2NOEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15b0bc64e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on validation set\n",
      "Got 884 / 1000 correct (88.40)\n"
     ]
    }
   ],
   "source": [
    "# Train your model here, and make sure the output of this cell is the accuracy of your best model on the \n",
    "# train, val, and test sets. Here's some code to get you started. The output of this cell should be the training\n",
    "# and validation accuracy on your best model (measured by validation accuracy).\n",
    "\n",
    "model_base = nn.Sequential(\n",
    "                    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(32, momentum=0.999), nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(32, momentum=0.999), nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64, momentum=0.999), nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(64, momentum=0.999), nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(128, momentum=0.999), nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(128, momentum=0.999), nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(256, momentum=0.999), nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                    nn.BatchNorm2d(256, momentum=0.999), nn.LeakyReLU(inplace=True),\n",
    "                    nn.Conv2d(256, 10, kernel_size=1, stride=1, padding=0),\n",
    "                    nn.AvgPool2d(4, stride=4),\n",
    "                    Flatten(),\n",
    "            )\n",
    "model = model_base.type(gpu_dtype)\n",
    "loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
    "optimizer = optim.SGD(model_base.parameters(), lr = 0.1, momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "\n",
    "train(model, loss_fn, optimizer, num_epochs=500, scheduler=scheduler, plot_losses=True)\n",
    "check_accuracy(model, loader_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe what you did \n",
    "\n",
    "In the cell below you should write an explanation of what you did, any additional features that you implemented, and any visualizations or graphs that you make in the process of training and evaluating your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A fully convolutional network with 9 conv layers and no fc layers.\n",
    "- The structure of each conv layer is conv-bn-act.\n",
    "- Only using 1x1 and 3x3 size of convolution kernels to reduce size of parameters.\n",
    "- Using stride 2 convolution instead of max pooling.\n",
    "- Using leaky relu as activation function.\n",
    "- Using L2 weight decay regularization.\n",
    "- Using data augmentation including left and right flipping and random croping to avoid overfitting.\n",
    "- Using SGD with momentum to optimize the network.\n",
    "- Decaying the learning rate to 1/10, when every time the loss function is slow and concussion, \n",
    "- The final accuracy on test sets is 87.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set -- run this only once\n",
    "\n",
    "Now that we've gotten a result we're happy with, we test our final model on the test set (which you should store in best_model).  This would be the score we would achieve on a competition. Think about how this compares to your validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Got 8774 / 10000 correct (87.74)\n"
     ]
    }
   ],
   "source": [
    "best_model = model\n",
    "check_accuracy(best_model, loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further with PyTorch\n",
    "\n",
    "The next assignment will make heavy use of PyTorch. You might also find it useful for your projects. \n",
    "\n",
    "Here's a nice tutorial by Justin Johnson that shows off some of PyTorch's features, like dynamic graphs and custom NN modules: http://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "\n",
    "If you're interested in reinforcement learning for your final project, this is a good (more advanced) DQN tutorial in PyTorch: http://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
